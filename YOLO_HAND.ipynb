{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilunga-k/AI-study/blob/main/YOLO_HAND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ï∂©Îèå Í∞ÄÎä• Ìå®ÌÇ§ÏßÄ Ï†ïÎ¶¨ ‚Üí Ìò∏Ìôò Î≤ÑÏ†Ñ ÏÑ§Ïπò ‚Üí ÏûêÎèô Ïû¨ÏãúÏûë\n",
        "!pip -q uninstall -y numpy opencv-python opencv-contrib-python opencv-python-headless ultralytics albumentations albucore thinc spacy fastai\n",
        "!pip -q install numpy==1.26.4 ultralytics==8.3.0 opencv-python-headless==4.11.0.86\n",
        "\n",
        "# W&B ÌîÑÎ°¨ÌîÑÌä∏ Î∞©ÏßÄ\n",
        "%env WANDB_DISABLED=true\n",
        "\n",
        "import os; os.kill(os.getpid(), 9)  # ÏûêÎèô Ïû¨ÏãúÏûë\n"
      ],
      "metadata": {
        "id": "60BYxesm7PRu",
        "outputId": "4669c6ad-5858-4b0c-c951-1340b63b5fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping albucore as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping thinc as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, cv2, ultralytics, os, glob, zipfile, shutil\n",
        "print(\"NumPy:\", np.__version__)       # 1.26.4 Í∂åÏû•\n",
        "print(\"OpenCV:\", cv2.__version__)     # 4.11.x\n",
        "print(\"Ultralytics:\", ultralytics.__version__)  # 8.3.0\n",
        "\n",
        "BASE = \"/content/hand_dataset\"  # ÏûëÏóÖ Î£®Ìä∏\n",
        "\n",
        "# zip ÏóÖÎ°úÎìú(Ïù¥ÎØ∏ ÌíÄÏóàÎã§Î©¥ Í±¥ÎÑàÎõ∞Ïñ¥ÎèÑ Îê®)\n",
        "from google.colab import files\n",
        "up = files.upload()  # hand_dataset.zip ÏÑ†ÌÉù\n",
        "\n",
        "zip_path = \"/content/\" + list(up.keys())[0]\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(\"/content\")\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î£®Ìä∏ ÏûêÎèô ÌÉêÏßÄ(train/val ÎòêÎäî vaild Ìè¨Ìï® Ìè¥Îçî)\n",
        "def looks_like_root(p):\n",
        "    return (os.path.isdir(f\"{p}/train/images\") and os.path.isdir(f\"{p}/train/labels\") and\n",
        "            (os.path.isdir(f\"{p}/val/images\") or os.path.isdir(f\"{p}/vaild/images\")) and\n",
        "            (os.path.isdir(f\"{p}/val/labels\") or os.path.isdir(f\"{p}/vaild/labels\")))\n",
        "cands = [d for d in glob.glob(\"/content/*\") if os.path.isdir(d)]\n",
        "root = next((d for d in sorted(cands, key=len) if looks_like_root(d)), None)\n",
        "assert root, \"Îç∞Ïù¥ÌÑ∞ Î£®Ìä∏Î•º Ï∞æÏßÄ Î™ªÌñàÏñ¥. zip ÎÇ¥Î∂Ä Íµ¨Ï°∞Î•º ÌôïÏù∏Ìï¥Ï§ò.\"\n",
        "\n",
        "# ÌëúÏ§Ä Í≤ΩÎ°úÎ°ú Ïù¥Îèô\n",
        "if os.path.abspath(root) != os.path.abspath(BASE):\n",
        "    if os.path.exists(BASE): shutil.rmtree(BASE)\n",
        "    shutil.move(root, BASE)\n",
        "\n",
        "# Ïò§ÌÉàÏûê Ìè¥Îçî ÍµêÏ†ï: vaild ‚Üí val\n",
        "if os.path.exists(f\"{BASE}/vaild\") and not os.path.exists(f\"{BASE}/val\"):\n",
        "    shutil.move(f\"{BASE}/vaild\", f\"{BASE}/val\")\n",
        "\n",
        "# Íµ¨Ï°∞ ÏµúÏ¢Ö ÌôïÏù∏\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    assert os.path.isdir(f\"{BASE}/{sp}/images\") and os.path.isdir(f\"{BASE}/{sp}/labels\"), f\"{sp} Ìè¥Îçî Íµ¨Ï°∞ Ïò§Î•ò\"\n",
        "print(\"Íµ¨Ï°∞ OK:\", BASE)\n"
      ],
      "metadata": {
        "id": "i6TIjZzc7vhq",
        "outputId": "cd2f8fb0-6211-4ff0-e6cc-6c0445f126d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 1.26.4\n",
            "OpenCV: 4.11.0\n",
            "Ultralytics: 8.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb019127-d48c-4b75-a6a8-f717a0720db3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb019127-d48c-4b75-a6a8-f717a0720db3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hand_dataset.zip to hand_dataset (2).zip\n",
            "Íµ¨Ï°∞ OK: /content/hand_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import json, math\n",
        "\n",
        "coco = YOLO(\"yolov8n.pt\")   # COCO ÏÇ¨Ï†ÑÌïôÏäµ\n",
        "TARGET_NAMES = {\"backpack\",\"handbag\",\"suitcase\"}\n",
        "CONF_THR = 0.35\n",
        "AREA_MIN_RATIO = 0.02   # ÎÑàÎ¨¥ ÏûëÏùÄ Í∞ÄÎ∞© Ï†úÍ±∞(ÌîÑÎ†àÏûÑ ÎåÄÎπÑ)\n",
        "\n",
        "def xyxy_to_yolo(x1,y1,x2,y2,W,H):\n",
        "    cx=(x1+x2)/2/W; cy=(y1+y2)/2/H; w=(x2-x1)/W; h=(y2-y1)/H\n",
        "    return cx,cy,w,h\n",
        "\n",
        "def image_list(img_dir):\n",
        "    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.JPG\",\"*.PNG\",\"*.JPEG\",\"*.BMP\")\n",
        "    lst = []\n",
        "    for e in exts: lst.extend(glob.glob(os.path.join(img_dir, e)))\n",
        "    return sorted(lst)\n",
        "\n",
        "def gen_pseudo(split):\n",
        "    img_dir = f\"{BASE}/{split}/images\"\n",
        "    made, found = 0, 0\n",
        "    for imgp in image_list(img_dir):\n",
        "        r = coco(imgp, conf=CONF_THR, iou=0.45, verbose=False)[0]\n",
        "        H, W = r.orig_shape\n",
        "        items = []\n",
        "        if r.boxes is not None and len(r.boxes) > 0:\n",
        "            for b, cls, conf in zip(r.boxes.xyxy.cpu().numpy(),\n",
        "                                    r.boxes.cls.cpu().numpy(),\n",
        "                                    r.boxes.conf.cpu().numpy()):\n",
        "                name = r.names[int(cls)].lower()\n",
        "                if name in TARGET_NAMES:\n",
        "                    x1,y1,x2,y2 = b\n",
        "                    if (x2-x1)*(y2-y1)/(W*H) >= AREA_MIN_RATIO:\n",
        "                        cx,cy,w,h = xyxy_to_yolo(x1,y1,x2,y2,W,H)\n",
        "                        items.append({\"name\":name,\"cx\":cx,\"cy\":cy,\"w\":w,\"h\":h,\"conf\":float(conf)})\n",
        "        # Í∏∞Ï°¥ hand ÎùºÎ≤® Î°úÎìú(ÏóÜÏúºÎ©¥ Îπà Î¶¨Ïä§Ìä∏)\n",
        "        lbl_path = imgp.replace(\"/images/\",\"/labels/\").rsplit(\".\",1)[0]+\".txt\"\n",
        "        hand_lines = []\n",
        "        if os.path.exists(lbl_path):\n",
        "            with open(lbl_path,\"r\") as f:\n",
        "                hand_lines = [ln.strip() for ln in f if ln.strip()]\n",
        "        # ÏûÑÏãú JSON Ï†ÄÏû•\n",
        "        meta_path = lbl_path.replace(\".txt\",\".json\")\n",
        "        with open(meta_path,\"w\") as f:\n",
        "            json.dump({\"hand_lines\":hand_lines,\"items\":items}, f)\n",
        "        made += 1; found += int(len(items)>0)\n",
        "    print(f\"[{split}] JSON {made}Í∞ú, Í∞ÄÎ∞© Í∞êÏßÄ Ìè¨Ìï® {found}Í∞ú\")\n",
        "\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    gen_pseudo(sp)\n",
        "print(\"ÏùòÏÇ¨ÎùºÎ≤®(JSON) ÏÉùÏÑ± ÏôÑÎ£å\")\n"
      ],
      "metadata": {
        "id": "nHRQ0aMT7iLC",
        "outputId": "649f0861-7796-4920-ce33-5ed0c5edda2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] JSON 491Í∞ú, Í∞ÄÎ∞© Í∞êÏßÄ Ìè¨Ìï® 0Í∞ú\n",
            "[val] JSON 58Í∞ú, Í∞ÄÎ∞© Í∞êÏßÄ Ìè¨Ìï® 0Í∞ú\n",
            "ÏùòÏÇ¨ÎùºÎ≤®(JSON) ÏÉùÏÑ± ÏôÑÎ£å\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, json\n",
        "\n",
        "CLASS_TO_IDX = {\"hand\":0, \"backpack\":1, \"handbag\":2, \"suitcase\":3}\n",
        "\n",
        "def merge_labels(split):\n",
        "    metas = sorted(glob.glob(f\"{BASE}/{split}/labels/*.json\"))\n",
        "    out_cnt = 0\n",
        "    for mp in metas:\n",
        "        meta = json.load(open(mp))\n",
        "        lines = []\n",
        "        # hand ÎùºÎ≤® ‚Üí class=0 Í∞ïÏ†ú ÌÜµÏùº\n",
        "        for ln in meta.get(\"hand_lines\", []):\n",
        "            ps = ln.split()\n",
        "            if not ps: continue\n",
        "            _, cx, cy, w, h = ps[:5]\n",
        "            lines.append(f\"{CLASS_TO_IDX['hand']} {cx} {cy} {w} {h}\")\n",
        "        # ÏùòÏÇ¨ÎùºÎ≤®(Í∞ÄÎ∞©Î•ò) Ï∂îÍ∞Ä\n",
        "        for it in meta.get(\"items\", []):\n",
        "            idx = CLASS_TO_IDX[it[\"name\"]]\n",
        "            lines.append(f\"{idx} {it['cx']:.6f} {it['cy']:.6f} {it['w']:.6f} {it['h']:.6f}\")\n",
        "        # ÏµúÏ¢Ö txt Ï†ÄÏû•\n",
        "        out_txt = mp.replace(\".json\",\".txt\")\n",
        "        with open(out_txt,\"w\") as f: f.write(\"\\n\".join(lines))\n",
        "        out_cnt += 1\n",
        "    print(f\"[{split}] ÏµúÏ¢Ö txt {out_cnt}Í∞ú ÏÉùÏÑ±/Í∞±Ïã†\")\n",
        "\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    merge_labels(sp)\n",
        "print(\"Î©ÄÌã∞ÌÅ¥ÎûòÏä§(txt) Î≥ëÌï© ÏôÑÎ£å\")\n",
        "\n",
        "# ÏÉà data.yaml (ÏõêÎ≥∏ yamlÏùÄ ÏàòÏ†ïÌïòÏßÄ ÏïäÏùå)\n",
        "yaml_text = f\"\"\"\\\n",
        "path: {BASE}\n",
        "train: train/images\n",
        "val: val/images\n",
        "nc: 4\n",
        "names: [hand, backpack, handbag, suitcase]\n",
        "\"\"\"\n",
        "open(f\"{BASE}/data.yaml\",\"w\").write(yaml_text)\n",
        "print(open(f\"{BASE}/data.yaml\").read())\n"
      ],
      "metadata": {
        "id": "7MHok7wN8RNX",
        "outputId": "913583c4-6b99-4578-a7c4-bb3ae89caba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] ÏµúÏ¢Ö txt 491Í∞ú ÏÉùÏÑ±/Í∞±Ïã†\n",
            "[val] ÏµúÏ¢Ö txt 58Í∞ú ÏÉùÏÑ±/Í∞±Ïã†\n",
            "Î©ÄÌã∞ÌÅ¥ÎûòÏä§(txt) Î≥ëÌï© ÏôÑÎ£å\n",
            "path: /content/hand_dataset\n",
            "train: train/images\n",
            "val: val/images\n",
            "nc: 4\n",
            "names: [hand, backpack, handbag, suitcase]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Îã®Í≥Ñ: Î∞±Î≥∏ Îã§Ïàò freeze(ÏùòÏÇ¨ÎùºÎ≤® Î∂àÌôïÏã§ÏÑ± ÏôÑÌôî)\n",
        "!yolo detect train \\\n",
        "  model=yolov8n.pt \\\n",
        "  data={BASE}/data.yaml \\\n",
        "  epochs=20 imgsz=640 batch=8 \\\n",
        "  lr0=0.002 weight_decay=0.0005 \\\n",
        "  freeze=10 \\\n",
        "  mosaic=0.8 mixup=0.05 degrees=5 translate=0.10 scale=0.5 shear=2 \\\n",
        "  cache=True\n",
        "\n",
        "# 2Îã®Í≥Ñ: unfreeze ÌõÑ ÎØ∏ÏÑ∏Ï°∞Ï†ï\n",
        "!yolo detect train \\\n",
        "  model=runs/detect/train/weights/best.pt \\\n",
        "  data={BASE}/data.yaml \\\n",
        "  epochs=40 imgsz=640 batch=8 \\\n",
        "  lr0=0.001 weight_decay=0.0005 \\\n",
        "  mosaic=0.6 mixup=0.0 degrees=5 translate=0.10 scale=0.5 shear=2 \\\n",
        "  cache=True\n"
      ],
      "metadata": {
        "id": "kmSFdwyb8Th-",
        "outputId": "13082ee5-3e9c-40ce-a57e-b3529f6ded1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.176 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.0 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/hand_dataset/data.yaml, epochs=20, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.002, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5, translate=0.1, scale=0.5, shear=2, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.8, mixup=0.05, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754881514.511449   15379 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754881514.517546   15379 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754881514.533628   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881514.533657   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881514.533660   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881514.533666   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 249 layers, 2,690,988 parameters, 2,690,972 gradients, 6.9 GFLOPs\n",
            "\n",
            "Transferred 313/391 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hand_dataset/train/labels... 491 images, 1 backgrounds, 0 corrupt: 100% 491/491 [00:00<00:00, 1876.43it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/hand_dataset/train/labels.cache\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB RAM): 100% 491/491 [00:02<00:00, 232.02it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hand_dataset/val/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100% 58/58 [00:00<?, ?it/s]\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100% 58/58 [00:00<00:00, 137.84it/s]\n",
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.002' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/20     0.717G      1.356      3.217      1.345         12        640: 100% 62/62 [00:09<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  5.98it/s]\n",
            "                   all         58        179      0.956      0.367      0.846      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/20     0.652G      1.271      1.565      1.225         17        640: 100% 62/62 [00:07<00:00,  8.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.23it/s]\n",
            "                   all         58        179      0.911      0.832       0.92      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/20     0.665G      1.183      1.249      1.163         17        640: 100% 62/62 [00:09<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  8.87it/s]\n",
            "                   all         58        179      0.824      0.844       0.91      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/20     0.663G      1.155      1.144      1.134         12        640: 100% 62/62 [00:08<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.15it/s]\n",
            "                   all         58        179      0.891      0.866      0.929      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/20     0.667G      1.104      1.082      1.135         10        640: 100% 62/62 [00:07<00:00,  8.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.49it/s]\n",
            "                   all         58        179      0.953      0.888      0.959      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/20      0.69G      1.085     0.9746      1.112         15        640: 100% 62/62 [00:08<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.67it/s]\n",
            "                   all         58        179      0.936      0.895      0.954      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/20     0.686G       1.08     0.9781      1.133         10        640: 100% 62/62 [00:08<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.06it/s]\n",
            "                   all         58        179      0.972      0.877      0.967      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/20     0.663G      1.064     0.9166      1.109         15        640: 100% 62/62 [00:07<00:00,  7.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.65it/s]\n",
            "                   all         58        179      0.942      0.902      0.959      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/20     0.659G      1.022     0.8993      1.092         30        640: 100% 62/62 [00:09<00:00,  6.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.15it/s]\n",
            "                   all         58        179      0.942      0.908      0.959      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/20     0.665G       1.02      0.862      1.079         24        640: 100% 62/62 [00:09<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.35it/s]\n",
            "                   all         58        179      0.961      0.916      0.962      0.643\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/20     0.705G      1.079     0.9871      1.092         10        640: 100% 62/62 [00:08<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.59it/s]\n",
            "                   all         58        179      0.986      0.899      0.969      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/20     0.661G      1.052     0.9105      1.065         10        640: 100% 62/62 [00:06<00:00,  8.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.99it/s]\n",
            "                   all         58        179      0.982      0.898      0.967      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/20     0.665G      1.048     0.8796      1.058         10        640: 100% 62/62 [00:07<00:00,  7.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.71it/s]\n",
            "                   all         58        179      0.961      0.899      0.973      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/20     0.665G      1.015     0.8417       1.05          6        640: 100% 62/62 [00:08<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.70it/s]\n",
            "                   all         58        179      0.976      0.901      0.977      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/20     0.665G      1.001     0.7877      1.033         11        640: 100% 62/62 [00:06<00:00,  8.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.85it/s]\n",
            "                   all         58        179      0.965      0.933      0.972      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/20     0.661G     0.9845     0.7751      1.021         11        640: 100% 62/62 [00:08<00:00,  7.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 12.14it/s]\n",
            "                   all         58        179      0.954      0.928      0.974      0.693\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/20     0.665G     0.9779     0.7611      1.019         10        640: 100% 62/62 [00:08<00:00,  7.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.13it/s]\n",
            "                   all         58        179      0.976      0.923      0.975      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/20     0.665G     0.9475     0.7388       1.01         10        640: 100% 62/62 [00:06<00:00,  8.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.86it/s]\n",
            "                   all         58        179      0.979      0.922      0.976      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/20     0.665G     0.9485     0.7179      1.002         11        640: 100% 62/62 [00:07<00:00,  7.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.99it/s]\n",
            "                   all         58        179      0.976      0.923      0.976      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/20     0.661G     0.9433     0.7115      1.008          9        640: 100% 62/62 [00:08<00:00,  7.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.60it/s]\n",
            "                   all         58        179      0.971      0.927      0.976      0.706\n",
            "\n",
            "20 epochs completed in 0.055 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 5.6MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 5.6MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics 8.3.0 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  3.62it/s]\n",
            "                   all         58        179      0.971      0.927      0.976      0.705\n",
            "                  hand         58        179      0.971      0.927      0.976      0.705\n",
            "Speed: 0.3ms preprocess, 3.5ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 7e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 7e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 7e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.97635\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.70524\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.92711\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 6.945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 2690988\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 5.458\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.94327\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.71146\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.00756\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.03166\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.56654\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.01039\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250811_030522-5ajses74\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20250811_030522-5ajses74/logs\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/train\n",
            "New https://pypi.org/project/ultralytics/8.3.176 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.0 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/train/weights/best.pt, data=/content/hand_dataset/data.yaml, epochs=40, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5, translate=0.1, scale=0.5, shear=2, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.6, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754881742.696521   16439 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754881742.703650   16439 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754881742.721671   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881742.721699   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881742.721702   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881742.721707   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 249 layers, 2,690,988 parameters, 2,690,972 gradients, 6.9 GFLOPs\n",
            "\n",
            "Transferred 391/391 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hand_dataset/train/labels.cache... 491 images, 1 backgrounds, 0 corrupt: 100% 491/491 [00:00<?, ?it/s]\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB RAM): 100% 491/491 [00:02<00:00, 187.29it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hand_dataset/val/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100% 58/58 [00:00<?, ?it/s]\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100% 58/58 [00:00<00:00, 87.11it/s] \n",
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/40      1.24G     0.9657     0.7371      1.033         12        640: 100% 62/62 [00:11<00:00,  5.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  8.42it/s]\n",
            "                   all         58        179      0.912      0.874      0.948       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/40      1.22G     0.9717     0.7255      1.047         18        640: 100% 62/62 [00:08<00:00,  7.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.29it/s]\n",
            "                   all         58        179      0.967      0.866      0.953      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/40      1.23G     0.9881     0.7462      1.062          9        640: 100% 62/62 [00:08<00:00,  7.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.23it/s]\n",
            "                   all         58        179      0.918      0.832      0.908       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/40      1.22G      1.035     0.7594      1.087         13        640: 100% 62/62 [00:09<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.52it/s]\n",
            "                   all         58        179      0.944      0.843      0.942      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/40      1.23G      1.001     0.7061      1.072         13        640: 100% 62/62 [00:09<00:00,  6.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.00it/s]\n",
            "                   all         58        179      0.926      0.866      0.945      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/40      1.23G     0.9639     0.6929      1.051         19        640: 100% 62/62 [00:08<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.48it/s]\n",
            "                   all         58        179      0.944      0.894      0.943      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/40      1.23G     0.9537     0.6664      1.049         21        640: 100% 62/62 [00:08<00:00,  7.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.49it/s]\n",
            "                   all         58        179       0.94      0.927      0.951      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/40      1.22G     0.9434      0.657      1.059          9        640: 100% 62/62 [00:10<00:00,  5.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.12it/s]\n",
            "                   all         58        179      0.965      0.894      0.968      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/40      1.23G     0.9774     0.6609      1.066         10        640: 100% 62/62 [00:09<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.37it/s]\n",
            "                   all         58        179      0.976      0.905      0.968      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/40      1.23G     0.9382     0.6188       1.04         11        640: 100% 62/62 [00:09<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.30it/s]\n",
            "                   all         58        179      0.951      0.871      0.954      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/40      1.23G     0.9161     0.5866      1.027         11        640: 100% 62/62 [00:08<00:00,  7.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.70it/s]\n",
            "                   all         58        179      0.963      0.911      0.965      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/40      1.22G     0.9094      0.585      1.027         15        640: 100% 62/62 [00:08<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.29it/s]\n",
            "                   all         58        179      0.953      0.902      0.965        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/40      1.23G     0.8816     0.5721      1.016         10        640: 100% 62/62 [00:09<00:00,  6.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.81it/s]\n",
            "                   all         58        179      0.966      0.911      0.962      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/40      1.23G      0.863     0.5406      1.004         14        640: 100% 62/62 [00:09<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.13it/s]\n",
            "                   all         58        179      0.963      0.927      0.975        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/40      1.23G     0.8737     0.5534      1.017         11        640: 100% 62/62 [00:07<00:00,  7.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.79it/s]\n",
            "                   all         58        179      0.953      0.933      0.977      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/40      1.22G     0.8696     0.5335      1.001         19        640: 100% 62/62 [00:09<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.23it/s]\n",
            "                   all         58        179      0.965      0.924      0.975      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/40      1.23G     0.8521     0.5276      1.004         20        640: 100% 62/62 [00:09<00:00,  6.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.43it/s]\n",
            "                   all         58        179      0.975      0.899      0.976      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/40      1.22G     0.8391     0.5196     0.9995         10        640: 100% 62/62 [00:09<00:00,  6.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.82it/s]\n",
            "                   all         58        179      0.981      0.933      0.982      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/40      1.23G     0.8225     0.4991     0.9894         18        640: 100% 62/62 [00:07<00:00,  7.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.29it/s]\n",
            "                   all         58        179      0.967      0.939      0.979      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/40      1.22G     0.8151     0.4985     0.9964          7        640: 100% 62/62 [00:08<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.44it/s]\n",
            "                   all         58        179      0.982      0.939      0.977      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/40      1.23G     0.8324     0.4972     0.9926         10        640: 100% 62/62 [00:09<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.74it/s]\n",
            "                   all         58        179      0.978      0.911      0.974      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/40      1.23G     0.8019     0.4853     0.9759         18        640: 100% 62/62 [00:09<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.26it/s]\n",
            "                   all         58        179       0.99      0.933      0.986      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/40      1.23G     0.7808     0.4723     0.9764         18        640: 100% 62/62 [00:07<00:00,  7.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  8.82it/s]\n",
            "                   all         58        179      0.988      0.943      0.983      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/40      1.22G     0.7649      0.454     0.9719         13        640: 100% 62/62 [00:08<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.45it/s]\n",
            "                   all         58        179      0.988      0.943      0.986      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/40      1.23G     0.7487      0.447     0.9605         13        640: 100% 62/62 [00:10<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.79it/s]\n",
            "                   all         58        179      0.994      0.927      0.984      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/40      1.23G     0.7527      0.449     0.9627         15        640: 100% 62/62 [00:09<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.49it/s]\n",
            "                   all         58        179      0.975      0.939      0.986      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/40      1.23G     0.7422     0.4384     0.9533         14        640: 100% 62/62 [00:07<00:00,  7.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.65it/s]\n",
            "                   all         58        179      0.963       0.95      0.989      0.763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/40      1.22G      0.749     0.4395     0.9557         23        640: 100% 62/62 [00:09<00:00,  6.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.80it/s]\n",
            "                   all         58        179      0.986       0.95      0.987      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/40      1.23G     0.7381     0.4326     0.9574          7        640: 100% 62/62 [00:09<00:00,  6.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.24it/s]\n",
            "                   all         58        179      0.983       0.96      0.991      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/40      1.23G     0.7212     0.4205     0.9527         19        640: 100% 62/62 [00:08<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  6.85it/s]\n",
            "                   all         58        179      0.983      0.955      0.989      0.744\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/40      1.23G     0.8213     0.4454     0.9746         10        640: 100% 62/62 [00:08<00:00,  7.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.73it/s]\n",
            "                   all         58        179      0.977      0.947      0.987      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/40      1.22G     0.8048      0.439      0.954         10        640: 100% 62/62 [00:08<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.68it/s]\n",
            "                   all         58        179      0.959      0.961      0.983      0.748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/40      1.23G     0.7995     0.4238     0.9525          7        640: 100% 62/62 [00:09<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.08it/s]\n",
            "                   all         58        179      0.992       0.95      0.991       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/40      1.23G     0.7913     0.4207      0.955         10        640: 100% 62/62 [00:08<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.65it/s]\n",
            "                   all         58        179      0.961      0.975      0.991       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/40      1.23G     0.7763     0.4158     0.9477          8        640: 100% 62/62 [00:07<00:00,  8.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.75it/s]\n",
            "                   all         58        179      0.946       0.97      0.991      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/40      1.22G     0.7697     0.4063     0.9407          8        640: 100% 62/62 [00:09<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.97it/s]\n",
            "                   all         58        179      0.955      0.957      0.988      0.759\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/40      1.23G     0.7604     0.4041     0.9351         10        640: 100% 62/62 [00:09<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.02it/s]\n",
            "                   all         58        179      0.975      0.966      0.991      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/40      1.23G      0.748     0.3863     0.9276          9        640: 100% 62/62 [00:08<00:00,  7.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.92it/s]\n",
            "                   all         58        179      0.976      0.961      0.991      0.756\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/40      1.23G     0.7334     0.3877     0.9266          8        640: 100% 62/62 [00:07<00:00,  7.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.34it/s]\n",
            "                   all         58        179      0.967      0.961      0.991      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/40      1.22G     0.7392     0.3867     0.9323          9        640: 100% 62/62 [00:09<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.87it/s]\n",
            "                   all         58        179      0.977      0.961      0.991      0.768\n",
            "\n",
            "40 epochs completed in 0.116 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 5.6MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 5.6MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics 8.3.0 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  3.47it/s]\n",
            "                   all         58        179      0.967      0.961      0.991      0.769\n",
            "                  hand         58        179      0.967      0.961      0.991      0.769\n",
            "Speed: 0.4ms preprocess, 4.8ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ‚ñÅ‚ñÜ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss ‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ‚ñá‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ‚ñà‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99056\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.76853\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96712\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.96089\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 6.945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 2690988\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 3.978\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.73922\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.38666\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.93233\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.86105\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.40026\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.98771\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250811_031106-ln7l1hqi\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20250811_031106-ln7l1hqi/logs\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Í≤ÄÏ¶ù\n",
        "!yolo detect val model=runs/detect/train2/weights/best.pt data={BASE}/data.yaml imgsz=640\n",
        "\n",
        "# ÏÉòÌîå ÏãúÍ∞ÅÌôî(ÏÑ†ÌÉù)\n",
        "!yolo detect predict model=runs/detect/train2/weights/best.pt source={BASE}/val/images conf=0.25 iou=0.45 save=True\n",
        "\n",
        "# ÌÅ¥ÎûòÏä§ ÌôïÏù∏\n",
        "from ultralytics import YOLO\n",
        "m = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
        "print(\"model.names:\", m.names)  # {0:'hand',1:'backpack',2:'handbag',3:'suitcase'} Í∏∞ÎåÄ\n",
        "\n",
        "# Îã§Ïö¥Î°úÎìú\n",
        "from google.colab import files\n",
        "files.download(\"runs/detect/train2/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "iqZEYf5Z-XAy",
        "outputId": "0d7d63fb-b0a1-4e0a-aebe-d8468c43c38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.0 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hand_dataset/val/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100% 58/58 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  2.42it/s]\n",
            "                   all         58        179      0.967      0.961      0.991      0.768\n",
            "                  hand         58        179      0.967      0.961      0.991      0.768\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics 8.3.0 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "\n",
            "image 1/58 /content/hand_dataset/val/images/CARDS_COURTYARD_S_H_frame_1054_jpg.rf.f91470b58278ac6f1e56b91c87a935ff.jpg: 384x640 2 hands, 41.0ms\n",
            "image 2/58 /content/hand_dataset/val/images/CARDS_COURTYARD_S_H_frame_2165_jpg.rf.bd435caea2048c037c0b10d2d6955613.jpg: 384x640 3 hands, 6.9ms\n",
            "image 3/58 /content/hand_dataset/val/images/CARDS_LIVINGROOM_B_T_frame_0374_jpg.rf.4c9f5356bfd2fe7fa6d0c7e5f7cc7feb.jpg: 384x640 4 hands, 6.3ms\n",
            "image 4/58 /content/hand_dataset/val/images/CARDS_LIVINGROOM_H_S_frame_1322_jpg.rf.3096a186973a0983541f6af55f7aba0b.jpg: 384x640 5 hands, 6.7ms\n",
            "image 5/58 /content/hand_dataset/val/images/CARDS_LIVINGROOM_T_B_frame_2273_jpg.rf.a3f4697b91561c3dab4aca964eaf13de.jpg: 384x640 2 hands, 6.2ms\n",
            "image 6/58 /content/hand_dataset/val/images/CARDS_OFFICE_B_S_frame_1674_jpg.rf.da760343a25c36078d4a0a99c6e41f15.jpg: 384x640 3 hands, 6.5ms\n",
            "image 7/58 /content/hand_dataset/val/images/CARDS_OFFICE_B_S_frame_2690_jpg.rf.cc890dbabeb8f05980db0d590ff5e88e.jpg: 384x640 4 hands, 6.4ms\n",
            "image 8/58 /content/hand_dataset/val/images/CARDS_OFFICE_T_H_frame_2116_jpg.rf.586e307de32fe5e7d9559684dedb76e4.jpg: 384x640 4 hands, 6.5ms\n",
            "image 9/58 /content/hand_dataset/val/images/CHESS_COURTYARD_B_T_frame_0413_jpg.rf.a3a3d7e4d40efc9209614b83a661cdb4.jpg: 384x640 3 hands, 6.4ms\n",
            "image 10/58 /content/hand_dataset/val/images/CHESS_COURTYARD_B_T_frame_0446_jpg.rf.d3ed18fc46b04eaeb9d0e0d6d687f567.jpg: 384x640 2 hands, 6.2ms\n",
            "image 11/58 /content/hand_dataset/val/images/CHESS_COURTYARD_B_T_frame_1110_jpg.rf.fc23abb80de77b1ff588891e6032f580.jpg: 384x640 2 hands, 6.0ms\n",
            "image 12/58 /content/hand_dataset/val/images/CHESS_COURTYARD_H_S_frame_0787_jpg.rf.b065ba2557637339210e47794207651e.jpg: 384x640 2 hands, 10.8ms\n",
            "image 13/58 /content/hand_dataset/val/images/CHESS_COURTYARD_H_S_frame_1297_jpg.rf.3c62abc5ec30506f78783d2b4ae25819.jpg: 384x640 3 hands, 9.0ms\n",
            "image 14/58 /content/hand_dataset/val/images/CHESS_COURTYARD_H_S_frame_2036_jpg.rf.17c461fbcd877468fd8572057f1bd6ff.jpg: 384x640 3 hands, 6.1ms\n",
            "image 15/58 /content/hand_dataset/val/images/CHESS_COURTYARD_S_H_frame_0453_jpg.rf.74b1804a7fc66e4b3a321afb0c4f7fb7.jpg: 384x640 2 hands, 6.0ms\n",
            "image 16/58 /content/hand_dataset/val/images/CHESS_COURTYARD_S_H_frame_2248_jpg.rf.e0e7936664617ca56fd6de1d2c1f333b.jpg: 384x640 2 hands, 6.2ms\n",
            "image 17/58 /content/hand_dataset/val/images/CHESS_COURTYARD_T_B_frame_1030_jpg.rf.7183851caea13c80b36fc1b1fa263426.jpg: 384x640 4 hands, 6.3ms\n",
            "image 18/58 /content/hand_dataset/val/images/CHESS_COURTYARD_T_B_frame_1194_jpg.rf.5cac6bdacc5fe5dfc608af9abbb6ddf5.jpg: 384x640 3 hands, 6.3ms\n",
            "image 19/58 /content/hand_dataset/val/images/CHESS_COURTYARD_T_B_frame_2546_jpg.rf.cdaf79bdcaabcb5f024f24530028f320.jpg: 384x640 4 hands, 6.3ms\n",
            "image 20/58 /content/hand_dataset/val/images/CHESS_OFFICE_B_S_frame_1535_jpg.rf.42159b1e4111903a09420afc3e3286a6.jpg: 384x640 4 hands, 6.1ms\n",
            "image 21/58 /content/hand_dataset/val/images/CHESS_OFFICE_B_S_frame_1915_jpg.rf.b037387a9c4c5663ab3f9af9cbb3c4c6.jpg: 384x640 3 hands, 6.2ms\n",
            "image 22/58 /content/hand_dataset/val/images/CHESS_OFFICE_H_T_frame_0693_jpg.rf.0ccee3e84f0d751c5d718abbd34c9293.jpg: 384x640 3 hands, 6.2ms\n",
            "image 23/58 /content/hand_dataset/val/images/CHESS_OFFICE_S_B_frame_1971_jpg.rf.d67d05549ba13f3d4800e95ea5b7cda8.jpg: 384x640 3 hands, 9.7ms\n",
            "image 24/58 /content/hand_dataset/val/images/CHESS_OFFICE_S_B_frame_2365_jpg.rf.228f876f7d6371b1225aae139e90e780.jpg: 384x640 2 hands, 7.5ms\n",
            "image 25/58 /content/hand_dataset/val/images/JENGA_COURTYARD_H_B_frame_2067_jpg.rf.baf066436cc4c8604dc64af3b2985d5f.jpg: 384x640 3 hands, 6.2ms\n",
            "image 26/58 /content/hand_dataset/val/images/JENGA_COURTYARD_H_B_frame_2087_jpg.rf.7134d68eec425c266a20b5adcbe057c6.jpg: 384x640 3 hands, 6.2ms\n",
            "image 27/58 /content/hand_dataset/val/images/JENGA_COURTYARD_S_T_frame_0813_jpg.rf.2917e50f7641658ddd39ddc71e5893ee.jpg: 384x640 4 hands, 6.4ms\n",
            "image 28/58 /content/hand_dataset/val/images/JENGA_COURTYARD_T_S_frame_1724_jpg.rf.71a7b06d5fb13ac04b418cb7b487ad84.jpg: 384x640 4 hands, 7.3ms\n",
            "image 29/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_B_H_frame_0784_jpg.rf.8140d4e9f08cad861c1d87b0e12ede64.jpg: 384x640 4 hands, 6.4ms\n",
            "image 30/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_B_H_frame_1185_jpg.rf.a4573e316e382b4bbeccc8983fd5b5ef.jpg: 384x640 4 hands, 6.2ms\n",
            "image 31/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_B_H_frame_1725_jpg.rf.d0eb7d8ef006fbb0f5e664f2c5718c73.jpg: 384x640 3 hands, 6.6ms\n",
            "image 32/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_H_B_frame_1425_jpg.rf.20c8a7581700814a4485bc141776e698.jpg: 384x640 1 hand, 6.6ms\n",
            "image 33/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_H_B_frame_1756_jpg.rf.566722ef918b3a83fe1f8983558a78ac.jpg: 384x640 4 hands, 6.9ms\n",
            "image 34/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_S_T_frame_0806_jpg.rf.fdc96738f5b3bd56d096db2bb5306e64.jpg: 384x640 2 hands, 6.7ms\n",
            "image 35/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_S_T_frame_0880_jpg.rf.64864a5cae51f5a80664421af47343d0.jpg: 384x640 4 hands, 6.4ms\n",
            "image 36/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_S_T_frame_2275_jpg.rf.611f28caf1db246fefe3ec049d9dfcc7.jpg: 384x640 4 hands, 7.1ms\n",
            "image 37/58 /content/hand_dataset/val/images/JENGA_OFFICE_S_B_frame_2573_jpg.rf.5209ab5ea582d724866bc065d9f7748f.jpg: 384x640 1 hand, 7.2ms\n",
            "image 38/58 /content/hand_dataset/val/images/JENGA_OFFICE_T_H_frame_1610_jpg.rf.6ba573834cc0d225f6622e7f3ff55118.jpg: 384x640 4 hands, 6.1ms\n",
            "image 39/58 /content/hand_dataset/val/images/JENGA_OFFICE_T_H_frame_1682_jpg.rf.7c06fd2f41ff51c0d6a010abeb1cb575.jpg: 384x640 3 hands, 6.4ms\n",
            "image 40/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_B_S_frame_1368_jpg.rf.bf21e17e67780b7625cc32fa87bc5b88.jpg: 384x640 4 hands, 6.3ms\n",
            "image 41/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_H_T_frame_1492_jpg.rf.c42eb255fddeaf955d4a9b006375c69c.jpg: 384x640 4 hands, 6.1ms\n",
            "image 42/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_S_B_frame_1906_jpg.rf.84fd2b46b1c19e93dd6ccbec8ef49c4b.jpg: 384x640 4 hands, 6.4ms\n",
            "image 43/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_0878_jpg.rf.93b2ba5631b7c806dac72d0cf5425e40.jpg: 384x640 3 hands, 6.6ms\n",
            "image 44/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_1037_jpg.rf.ee5d1d5edce69b6bbd02fdd1bb897197.jpg: 384x640 2 hands, 6.3ms\n",
            "image 45/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_1281_jpg.rf.7d81546e8de75e82752d3a5afb6e777d.jpg: 384x640 2 hands, 6.5ms\n",
            "image 46/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_1894_jpg.rf.00efae11da8a6c9fa6b1fca4e2c9f66f.jpg: 384x640 3 hands, 6.3ms\n",
            "image 47/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_B_T_frame_1279_jpg.rf.ab5f9c49880d2ccd8db9b4dfccec0e00.jpg: 384x640 4 hands, 6.2ms\n",
            "image 48/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_H_S_frame_1162_jpg.rf.5e3b1c555b60f7909c727ad1a2d24684.jpg: 384x640 1 hand, 6.1ms\n",
            "image 49/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_S_H_frame_0381_jpg.rf.3e42cb3f93048afb67924fe598f25d8c.jpg: 384x640 3 hands, 8.3ms\n",
            "image 50/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_S_H_frame_1607_jpg.rf.54fb53b8024faf86d7feddb4e56b03a7.jpg: 384x640 2 hands, 6.4ms\n",
            "image 51/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_S_H_frame_2352_jpg.rf.07783dc544293177f5566c857027c6aa.jpg: 384x640 4 hands, 6.2ms\n",
            "image 52/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_T_B_frame_1582_jpg.rf.3d7bfd0e4255e2ec50027e7164006410.jpg: 384x640 4 hands, 6.1ms\n",
            "image 53/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_T_B_frame_2151_jpg.rf.ed2752504e1745a8218276e0c2b112ed.jpg: 384x640 3 hands, 6.2ms\n",
            "image 54/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_T_B_frame_2567_jpg.rf.ca25ec8413398f59907a2120e53375f0.jpg: 384x640 3 hands, 6.1ms\n",
            "image 55/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_B_H_frame_2537_jpg.rf.e22dcb5a43b77e8748df1ba3265ce42d.jpg: 384x640 3 hands, 6.2ms\n",
            "image 56/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_H_B_frame_1977_jpg.rf.9d65b4edcfc134c078857da47c138e47.jpg: 384x640 4 hands, 8.1ms\n",
            "image 57/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_H_B_frame_2319_jpg.rf.adb78752e0a44c15f0ccebdf416baa2b.jpg: 384x640 1 hand, 7.2ms\n",
            "image 58/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_T_S_frame_0378_jpg.rf.3b9927a17fa5727d181e9c0c80549914.jpg: 384x640 4 hands, 6.2ms\n",
            "Speed: 1.7ms preprocess, 7.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/predict\n",
            "model.names: {0: 'hand', 1: 'backpack', 2: 'handbag', 3: 'suitcase'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42c7076c-f8cb-46af-b224-7eb001927fdf\", \"best.pt\", 5598767)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}