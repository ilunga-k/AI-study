{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilunga-k/AI-study/blob/main/YOLO_HAND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 충돌 가능 패키지 정리 → 호환 버전 설치 → 자동 재시작\n",
        "!pip -q uninstall -y numpy opencv-python opencv-contrib-python opencv-python-headless ultralytics albumentations albucore thinc spacy fastai\n",
        "!pip -q install numpy==1.26.4 ultralytics==8.3.0 opencv-python-headless==4.11.0.86\n",
        "\n",
        "# W&B 프롬프트 방지\n",
        "%env WANDB_DISABLED=true\n",
        "\n",
        "import os; os.kill(os.getpid(), 9)  # 자동 재시작\n"
      ],
      "metadata": {
        "id": "60BYxesm7PRu",
        "outputId": "4669c6ad-5858-4b0c-c951-1340b63b5fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping albucore as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping thinc as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, cv2, ultralytics, os, glob, zipfile, shutil\n",
        "print(\"NumPy:\", np.__version__)       # 1.26.4 권장\n",
        "print(\"OpenCV:\", cv2.__version__)     # 4.11.x\n",
        "print(\"Ultralytics:\", ultralytics.__version__)  # 8.3.0\n",
        "\n",
        "BASE = \"/content/hand_dataset\"  # 작업 루트\n",
        "\n",
        "# zip 업로드(이미 풀었다면 건너뛰어도 됨)\n",
        "from google.colab import files\n",
        "up = files.upload()  # hand_dataset.zip 선택\n",
        "\n",
        "zip_path = \"/content/\" + list(up.keys())[0]\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(\"/content\")\n",
        "\n",
        "# 데이터 루트 자동 탐지(train/val 또는 vaild 포함 폴더)\n",
        "def looks_like_root(p):\n",
        "    return (os.path.isdir(f\"{p}/train/images\") and os.path.isdir(f\"{p}/train/labels\") and\n",
        "            (os.path.isdir(f\"{p}/val/images\") or os.path.isdir(f\"{p}/vaild/images\")) and\n",
        "            (os.path.isdir(f\"{p}/val/labels\") or os.path.isdir(f\"{p}/vaild/labels\")))\n",
        "cands = [d for d in glob.glob(\"/content/*\") if os.path.isdir(d)]\n",
        "root = next((d for d in sorted(cands, key=len) if looks_like_root(d)), None)\n",
        "assert root, \"데이터 루트를 찾지 못했어. zip 내부 구조를 확인해줘.\"\n",
        "\n",
        "# 표준 경로로 이동\n",
        "if os.path.abspath(root) != os.path.abspath(BASE):\n",
        "    if os.path.exists(BASE): shutil.rmtree(BASE)\n",
        "    shutil.move(root, BASE)\n",
        "\n",
        "# 오탈자 폴더 교정: vaild → val\n",
        "if os.path.exists(f\"{BASE}/vaild\") and not os.path.exists(f\"{BASE}/val\"):\n",
        "    shutil.move(f\"{BASE}/vaild\", f\"{BASE}/val\")\n",
        "\n",
        "# 구조 최종 확인\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    assert os.path.isdir(f\"{BASE}/{sp}/images\") and os.path.isdir(f\"{BASE}/{sp}/labels\"), f\"{sp} 폴더 구조 오류\"\n",
        "print(\"구조 OK:\", BASE)\n"
      ],
      "metadata": {
        "id": "i6TIjZzc7vhq",
        "outputId": "cd2f8fb0-6211-4ff0-e6cc-6c0445f126d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 1.26.4\n",
            "OpenCV: 4.11.0\n",
            "Ultralytics: 8.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb019127-d48c-4b75-a6a8-f717a0720db3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb019127-d48c-4b75-a6a8-f717a0720db3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hand_dataset.zip to hand_dataset (2).zip\n",
            "구조 OK: /content/hand_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import json, math\n",
        "\n",
        "coco = YOLO(\"yolov8n.pt\")   # COCO 사전학습\n",
        "TARGET_NAMES = {\"backpack\",\"handbag\",\"suitcase\"}\n",
        "CONF_THR = 0.35\n",
        "AREA_MIN_RATIO = 0.02   # 너무 작은 가방 제거(프레임 대비)\n",
        "\n",
        "def xyxy_to_yolo(x1,y1,x2,y2,W,H):\n",
        "    cx=(x1+x2)/2/W; cy=(y1+y2)/2/H; w=(x2-x1)/W; h=(y2-y1)/H\n",
        "    return cx,cy,w,h\n",
        "\n",
        "def image_list(img_dir):\n",
        "    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.JPG\",\"*.PNG\",\"*.JPEG\",\"*.BMP\")\n",
        "    lst = []\n",
        "    for e in exts: lst.extend(glob.glob(os.path.join(img_dir, e)))\n",
        "    return sorted(lst)\n",
        "\n",
        "def gen_pseudo(split):\n",
        "    img_dir = f\"{BASE}/{split}/images\"\n",
        "    made, found = 0, 0\n",
        "    for imgp in image_list(img_dir):\n",
        "        r = coco(imgp, conf=CONF_THR, iou=0.45, verbose=False)[0]\n",
        "        H, W = r.orig_shape\n",
        "        items = []\n",
        "        if r.boxes is not None and len(r.boxes) > 0:\n",
        "            for b, cls, conf in zip(r.boxes.xyxy.cpu().numpy(),\n",
        "                                    r.boxes.cls.cpu().numpy(),\n",
        "                                    r.boxes.conf.cpu().numpy()):\n",
        "                name = r.names[int(cls)].lower()\n",
        "                if name in TARGET_NAMES:\n",
        "                    x1,y1,x2,y2 = b\n",
        "                    if (x2-x1)*(y2-y1)/(W*H) >= AREA_MIN_RATIO:\n",
        "                        cx,cy,w,h = xyxy_to_yolo(x1,y1,x2,y2,W,H)\n",
        "                        items.append({\"name\":name,\"cx\":cx,\"cy\":cy,\"w\":w,\"h\":h,\"conf\":float(conf)})\n",
        "        # 기존 hand 라벨 로드(없으면 빈 리스트)\n",
        "        lbl_path = imgp.replace(\"/images/\",\"/labels/\").rsplit(\".\",1)[0]+\".txt\"\n",
        "        hand_lines = []\n",
        "        if os.path.exists(lbl_path):\n",
        "            with open(lbl_path,\"r\") as f:\n",
        "                hand_lines = [ln.strip() for ln in f if ln.strip()]\n",
        "        # 임시 JSON 저장\n",
        "        meta_path = lbl_path.replace(\".txt\",\".json\")\n",
        "        with open(meta_path,\"w\") as f:\n",
        "            json.dump({\"hand_lines\":hand_lines,\"items\":items}, f)\n",
        "        made += 1; found += int(len(items)>0)\n",
        "    print(f\"[{split}] JSON {made}개, 가방 감지 포함 {found}개\")\n",
        "\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    gen_pseudo(sp)\n",
        "print(\"의사라벨(JSON) 생성 완료\")\n"
      ],
      "metadata": {
        "id": "nHRQ0aMT7iLC",
        "outputId": "649f0861-7796-4920-ce33-5ed0c5edda2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] JSON 491개, 가방 감지 포함 0개\n",
            "[val] JSON 58개, 가방 감지 포함 0개\n",
            "의사라벨(JSON) 생성 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, json\n",
        "\n",
        "CLASS_TO_IDX = {\"hand\":0, \"backpack\":1, \"handbag\":2, \"suitcase\":3}\n",
        "\n",
        "def merge_labels(split):\n",
        "    metas = sorted(glob.glob(f\"{BASE}/{split}/labels/*.json\"))\n",
        "    out_cnt = 0\n",
        "    for mp in metas:\n",
        "        meta = json.load(open(mp))\n",
        "        lines = []\n",
        "        # hand 라벨 → class=0 강제 통일\n",
        "        for ln in meta.get(\"hand_lines\", []):\n",
        "            ps = ln.split()\n",
        "            if not ps: continue\n",
        "            _, cx, cy, w, h = ps[:5]\n",
        "            lines.append(f\"{CLASS_TO_IDX['hand']} {cx} {cy} {w} {h}\")\n",
        "        # 의사라벨(가방류) 추가\n",
        "        for it in meta.get(\"items\", []):\n",
        "            idx = CLASS_TO_IDX[it[\"name\"]]\n",
        "            lines.append(f\"{idx} {it['cx']:.6f} {it['cy']:.6f} {it['w']:.6f} {it['h']:.6f}\")\n",
        "        # 최종 txt 저장\n",
        "        out_txt = mp.replace(\".json\",\".txt\")\n",
        "        with open(out_txt,\"w\") as f: f.write(\"\\n\".join(lines))\n",
        "        out_cnt += 1\n",
        "    print(f\"[{split}] 최종 txt {out_cnt}개 생성/갱신\")\n",
        "\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    merge_labels(sp)\n",
        "print(\"멀티클래스(txt) 병합 완료\")\n",
        "\n",
        "# 새 data.yaml (원본 yaml은 수정하지 않음)\n",
        "yaml_text = f\"\"\"\\\n",
        "path: {BASE}\n",
        "train: train/images\n",
        "val: val/images\n",
        "nc: 4\n",
        "names: [hand, backpack, handbag, suitcase]\n",
        "\"\"\"\n",
        "open(f\"{BASE}/data.yaml\",\"w\").write(yaml_text)\n",
        "print(open(f\"{BASE}/data.yaml\").read())\n"
      ],
      "metadata": {
        "id": "7MHok7wN8RNX",
        "outputId": "913583c4-6b99-4578-a7c4-bb3ae89caba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 최종 txt 491개 생성/갱신\n",
            "[val] 최종 txt 58개 생성/갱신\n",
            "멀티클래스(txt) 병합 완료\n",
            "path: /content/hand_dataset\n",
            "train: train/images\n",
            "val: val/images\n",
            "nc: 4\n",
            "names: [hand, backpack, handbag, suitcase]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1단계: 백본 다수 freeze(의사라벨 불확실성 완화)\n",
        "!yolo detect train \\\n",
        "  model=yolov8n.pt \\\n",
        "  data={BASE}/data.yaml \\\n",
        "  epochs=20 imgsz=640 batch=8 \\\n",
        "  lr0=0.002 weight_decay=0.0005 \\\n",
        "  freeze=10 \\\n",
        "  mosaic=0.8 mixup=0.05 degrees=5 translate=0.10 scale=0.5 shear=2 \\\n",
        "  cache=True\n",
        "\n",
        "# 2단계: unfreeze 후 미세조정\n",
        "!yolo detect train \\\n",
        "  model=runs/detect/train/weights/best.pt \\\n",
        "  data={BASE}/data.yaml \\\n",
        "  epochs=40 imgsz=640 batch=8 \\\n",
        "  lr0=0.001 weight_decay=0.0005 \\\n",
        "  mosaic=0.6 mixup=0.0 degrees=5 translate=0.10 scale=0.5 shear=2 \\\n",
        "  cache=True\n"
      ],
      "metadata": {
        "id": "kmSFdwyb8Th-",
        "outputId": "13082ee5-3e9c-40ce-a57e-b3529f6ded1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.176 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.0 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/hand_dataset/data.yaml, epochs=20, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.002, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5, translate=0.1, scale=0.5, shear=2, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.8, mixup=0.05, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754881514.511449   15379 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754881514.517546   15379 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754881514.533628   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881514.533657   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881514.533660   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881514.533666   15379 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 249 layers, 2,690,988 parameters, 2,690,972 gradients, 6.9 GFLOPs\n",
            "\n",
            "Transferred 313/391 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hand_dataset/train/labels... 491 images, 1 backgrounds, 0 corrupt: 100% 491/491 [00:00<00:00, 1876.43it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/hand_dataset/train/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB RAM): 100% 491/491 [00:02<00:00, 232.02it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hand_dataset/val/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100% 58/58 [00:00<?, ?it/s]\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100% 58/58 [00:00<00:00, 137.84it/s]\n",
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.002' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/20     0.717G      1.356      3.217      1.345         12        640: 100% 62/62 [00:09<00:00,  6.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  5.98it/s]\n",
            "                   all         58        179      0.956      0.367      0.846      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/20     0.652G      1.271      1.565      1.225         17        640: 100% 62/62 [00:07<00:00,  8.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.23it/s]\n",
            "                   all         58        179      0.911      0.832       0.92      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/20     0.665G      1.183      1.249      1.163         17        640: 100% 62/62 [00:09<00:00,  6.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  8.87it/s]\n",
            "                   all         58        179      0.824      0.844       0.91      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/20     0.663G      1.155      1.144      1.134         12        640: 100% 62/62 [00:08<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.15it/s]\n",
            "                   all         58        179      0.891      0.866      0.929      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/20     0.667G      1.104      1.082      1.135         10        640: 100% 62/62 [00:07<00:00,  8.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.49it/s]\n",
            "                   all         58        179      0.953      0.888      0.959      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/20      0.69G      1.085     0.9746      1.112         15        640: 100% 62/62 [00:08<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.67it/s]\n",
            "                   all         58        179      0.936      0.895      0.954      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/20     0.686G       1.08     0.9781      1.133         10        640: 100% 62/62 [00:08<00:00,  6.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.06it/s]\n",
            "                   all         58        179      0.972      0.877      0.967      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/20     0.663G      1.064     0.9166      1.109         15        640: 100% 62/62 [00:07<00:00,  7.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.65it/s]\n",
            "                   all         58        179      0.942      0.902      0.959      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/20     0.659G      1.022     0.8993      1.092         30        640: 100% 62/62 [00:09<00:00,  6.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.15it/s]\n",
            "                   all         58        179      0.942      0.908      0.959      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/20     0.665G       1.02      0.862      1.079         24        640: 100% 62/62 [00:09<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.35it/s]\n",
            "                   all         58        179      0.961      0.916      0.962      0.643\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/20     0.705G      1.079     0.9871      1.092         10        640: 100% 62/62 [00:08<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.59it/s]\n",
            "                   all         58        179      0.986      0.899      0.969      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/20     0.661G      1.052     0.9105      1.065         10        640: 100% 62/62 [00:06<00:00,  8.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.99it/s]\n",
            "                   all         58        179      0.982      0.898      0.967      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/20     0.665G      1.048     0.8796      1.058         10        640: 100% 62/62 [00:07<00:00,  7.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.71it/s]\n",
            "                   all         58        179      0.961      0.899      0.973      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/20     0.665G      1.015     0.8417       1.05          6        640: 100% 62/62 [00:08<00:00,  7.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.70it/s]\n",
            "                   all         58        179      0.976      0.901      0.977      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/20     0.665G      1.001     0.7877      1.033         11        640: 100% 62/62 [00:06<00:00,  8.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.85it/s]\n",
            "                   all         58        179      0.965      0.933      0.972      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/20     0.661G     0.9845     0.7751      1.021         11        640: 100% 62/62 [00:08<00:00,  7.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 12.14it/s]\n",
            "                   all         58        179      0.954      0.928      0.974      0.693\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/20     0.665G     0.9779     0.7611      1.019         10        640: 100% 62/62 [00:08<00:00,  7.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.13it/s]\n",
            "                   all         58        179      0.976      0.923      0.975      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/20     0.665G     0.9475     0.7388       1.01         10        640: 100% 62/62 [00:06<00:00,  8.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.86it/s]\n",
            "                   all         58        179      0.979      0.922      0.976      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/20     0.665G     0.9485     0.7179      1.002         11        640: 100% 62/62 [00:07<00:00,  7.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  9.99it/s]\n",
            "                   all         58        179      0.976      0.923      0.976      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/20     0.661G     0.9433     0.7115      1.008          9        640: 100% 62/62 [00:08<00:00,  7.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.60it/s]\n",
            "                   all         58        179      0.971      0.927      0.976      0.706\n",
            "\n",
            "20 epochs completed in 0.055 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 5.6MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 5.6MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics 8.3.0 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  3.62it/s]\n",
            "                   all         58        179      0.971      0.927      0.976      0.705\n",
            "                  hand         58        179      0.971      0.927      0.976      0.705\n",
            "Speed: 0.3ms preprocess, 3.5ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ▃▆██▇▇▆▆▆▅▅▄▄▃▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▃▆██▇▇▆▆▆▅▅▄▄▃▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▃▆██▇▇▆▆▆▅▅▄▄▃▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▅▄▅▇▇▇▇▇▇█▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▅▄▄▇▇▅▇▆▅▇▆▇▇█▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▇▅▁▄▇▆▇▆▆▇██▇█▇▇███▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▇▇▇▇█▇█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▅▅▄▃▃▃▂▂▃▃▃▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▃▃▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▄▄▄▃▄▃▃▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▅▅▅▇▄▃█▄▄▇▃▅▃▄▂▂▃▁▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▄▄▄█▅▄▇▄▄▇▃▅▄▄▃▂▂▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 7e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 7e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 7e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.97635\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.70524\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.97075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.92711\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 6.945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 2690988\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 5.458\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.94327\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.71146\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.00756\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 1.03166\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.56654\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 1.01039\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250811_030522-5ajses74\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20250811_030522-5ajses74/logs\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n",
            "New https://pypi.org/project/ultralytics/8.3.176 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.0 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/train/weights/best.pt, data=/content/hand_dataset/data.yaml, epochs=40, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5, translate=0.1, scale=0.5, shear=2, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.6, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754881742.696521   16439 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754881742.703650   16439 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754881742.721671   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881742.721699   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881742.721702   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754881742.721707   16439 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 249 layers, 2,690,988 parameters, 2,690,972 gradients, 6.9 GFLOPs\n",
            "\n",
            "Transferred 391/391 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hand_dataset/train/labels.cache... 491 images, 1 backgrounds, 0 corrupt: 100% 491/491 [00:00<?, ?it/s]\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB RAM): 100% 491/491 [00:02<00:00, 187.29it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hand_dataset/val/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100% 58/58 [00:00<?, ?it/s]\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100% 58/58 [00:00<00:00, 87.11it/s] \n",
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/40      1.24G     0.9657     0.7371      1.033         12        640: 100% 62/62 [00:11<00:00,  5.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  8.42it/s]\n",
            "                   all         58        179      0.912      0.874      0.948       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/40      1.22G     0.9717     0.7255      1.047         18        640: 100% 62/62 [00:08<00:00,  7.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.29it/s]\n",
            "                   all         58        179      0.967      0.866      0.953      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/40      1.23G     0.9881     0.7462      1.062          9        640: 100% 62/62 [00:08<00:00,  7.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.23it/s]\n",
            "                   all         58        179      0.918      0.832      0.908       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/40      1.22G      1.035     0.7594      1.087         13        640: 100% 62/62 [00:09<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.52it/s]\n",
            "                   all         58        179      0.944      0.843      0.942      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/40      1.23G      1.001     0.7061      1.072         13        640: 100% 62/62 [00:09<00:00,  6.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.00it/s]\n",
            "                   all         58        179      0.926      0.866      0.945      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/40      1.23G     0.9639     0.6929      1.051         19        640: 100% 62/62 [00:08<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.48it/s]\n",
            "                   all         58        179      0.944      0.894      0.943      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/40      1.23G     0.9537     0.6664      1.049         21        640: 100% 62/62 [00:08<00:00,  7.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.49it/s]\n",
            "                   all         58        179       0.94      0.927      0.951      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/40      1.22G     0.9434      0.657      1.059          9        640: 100% 62/62 [00:10<00:00,  5.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.12it/s]\n",
            "                   all         58        179      0.965      0.894      0.968      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/40      1.23G     0.9774     0.6609      1.066         10        640: 100% 62/62 [00:09<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.37it/s]\n",
            "                   all         58        179      0.976      0.905      0.968      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/40      1.23G     0.9382     0.6188       1.04         11        640: 100% 62/62 [00:09<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.30it/s]\n",
            "                   all         58        179      0.951      0.871      0.954      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/40      1.23G     0.9161     0.5866      1.027         11        640: 100% 62/62 [00:08<00:00,  7.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.70it/s]\n",
            "                   all         58        179      0.963      0.911      0.965      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/40      1.22G     0.9094      0.585      1.027         15        640: 100% 62/62 [00:08<00:00,  6.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.29it/s]\n",
            "                   all         58        179      0.953      0.902      0.965        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/40      1.23G     0.8816     0.5721      1.016         10        640: 100% 62/62 [00:09<00:00,  6.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.81it/s]\n",
            "                   all         58        179      0.966      0.911      0.962      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/40      1.23G      0.863     0.5406      1.004         14        640: 100% 62/62 [00:09<00:00,  6.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.13it/s]\n",
            "                   all         58        179      0.963      0.927      0.975        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/40      1.23G     0.8737     0.5534      1.017         11        640: 100% 62/62 [00:07<00:00,  7.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.79it/s]\n",
            "                   all         58        179      0.953      0.933      0.977      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/40      1.22G     0.8696     0.5335      1.001         19        640: 100% 62/62 [00:09<00:00,  6.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.23it/s]\n",
            "                   all         58        179      0.965      0.924      0.975      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/40      1.23G     0.8521     0.5276      1.004         20        640: 100% 62/62 [00:09<00:00,  6.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.43it/s]\n",
            "                   all         58        179      0.975      0.899      0.976      0.697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/40      1.22G     0.8391     0.5196     0.9995         10        640: 100% 62/62 [00:09<00:00,  6.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.82it/s]\n",
            "                   all         58        179      0.981      0.933      0.982      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/40      1.23G     0.8225     0.4991     0.9894         18        640: 100% 62/62 [00:07<00:00,  7.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.29it/s]\n",
            "                   all         58        179      0.967      0.939      0.979      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/40      1.22G     0.8151     0.4985     0.9964          7        640: 100% 62/62 [00:08<00:00,  6.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.44it/s]\n",
            "                   all         58        179      0.982      0.939      0.977      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/40      1.23G     0.8324     0.4972     0.9926         10        640: 100% 62/62 [00:09<00:00,  6.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.74it/s]\n",
            "                   all         58        179      0.978      0.911      0.974      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/40      1.23G     0.8019     0.4853     0.9759         18        640: 100% 62/62 [00:09<00:00,  6.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.26it/s]\n",
            "                   all         58        179       0.99      0.933      0.986      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/40      1.23G     0.7808     0.4723     0.9764         18        640: 100% 62/62 [00:07<00:00,  7.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  8.82it/s]\n",
            "                   all         58        179      0.988      0.943      0.983      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/40      1.22G     0.7649      0.454     0.9719         13        640: 100% 62/62 [00:08<00:00,  7.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.45it/s]\n",
            "                   all         58        179      0.988      0.943      0.986      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/40      1.23G     0.7487      0.447     0.9605         13        640: 100% 62/62 [00:10<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.79it/s]\n",
            "                   all         58        179      0.994      0.927      0.984      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/40      1.23G     0.7527      0.449     0.9627         15        640: 100% 62/62 [00:09<00:00,  6.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.49it/s]\n",
            "                   all         58        179      0.975      0.939      0.986      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/40      1.23G     0.7422     0.4384     0.9533         14        640: 100% 62/62 [00:07<00:00,  7.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.65it/s]\n",
            "                   all         58        179      0.963       0.95      0.989      0.763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/40      1.22G      0.749     0.4395     0.9557         23        640: 100% 62/62 [00:09<00:00,  6.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.80it/s]\n",
            "                   all         58        179      0.986       0.95      0.987      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/40      1.23G     0.7381     0.4326     0.9574          7        640: 100% 62/62 [00:09<00:00,  6.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.24it/s]\n",
            "                   all         58        179      0.983       0.96      0.991      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/40      1.23G     0.7212     0.4205     0.9527         19        640: 100% 62/62 [00:08<00:00,  6.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  6.85it/s]\n",
            "                   all         58        179      0.983      0.955      0.989      0.744\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/40      1.23G     0.8213     0.4454     0.9746         10        640: 100% 62/62 [00:08<00:00,  7.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.73it/s]\n",
            "                   all         58        179      0.977      0.947      0.987      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/40      1.22G     0.8048      0.439      0.954         10        640: 100% 62/62 [00:08<00:00,  7.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.68it/s]\n",
            "                   all         58        179      0.959      0.961      0.983      0.748\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/40      1.23G     0.7995     0.4238     0.9525          7        640: 100% 62/62 [00:09<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.08it/s]\n",
            "                   all         58        179      0.992       0.95      0.991       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/40      1.23G     0.7913     0.4207      0.955         10        640: 100% 62/62 [00:08<00:00,  6.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.65it/s]\n",
            "                   all         58        179      0.961      0.975      0.991       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/40      1.23G     0.7763     0.4158     0.9477          8        640: 100% 62/62 [00:07<00:00,  8.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.75it/s]\n",
            "                   all         58        179      0.946       0.97      0.991      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/40      1.22G     0.7697     0.4063     0.9407          8        640: 100% 62/62 [00:09<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 10.97it/s]\n",
            "                   all         58        179      0.955      0.957      0.988      0.759\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/40      1.23G     0.7604     0.4041     0.9351         10        640: 100% 62/62 [00:09<00:00,  6.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.02it/s]\n",
            "                   all         58        179      0.975      0.966      0.991      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/40      1.23G      0.748     0.3863     0.9276          9        640: 100% 62/62 [00:08<00:00,  7.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00,  7.92it/s]\n",
            "                   all         58        179      0.976      0.961      0.991      0.756\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/40      1.23G     0.7334     0.3877     0.9266          8        640: 100% 62/62 [00:07<00:00,  7.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.34it/s]\n",
            "                   all         58        179      0.967      0.961      0.991      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/40      1.22G     0.7392     0.3867     0.9323          9        640: 100% 62/62 [00:09<00:00,  6.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:00<00:00, 11.87it/s]\n",
            "                   all         58        179      0.977      0.961      0.991      0.768\n",
            "\n",
            "40 epochs completed in 0.116 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 5.6MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 5.6MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics 8.3.0 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  3.47it/s]\n",
            "                   all         58        179      0.967      0.961      0.991      0.769\n",
            "                  hand         58        179      0.967      0.961      0.991      0.769\n",
            "Speed: 0.4ms preprocess, 4.8ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▄▅▁▄▄▄▅▆▆▅▆▆▆▇▇▇▇▇▇▇▇█▇█▇██████▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▃▃▁▂▁▂▃▄▄▃▄▄▄▄▅▅▄▇▅▆▅▆▇▇▇▇█▇▆▇▇▇▇█▇█▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▁▆▁▄▂▄▃▆▆▄▅▄▆▅▄▆▆▇▆▇▇████▆▅▇▇▇▇▅█▅▄▅▆▆▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▃▃▁▂▃▄▆▄▅▃▅▄▅▆▆▆▄▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇██▇█▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss ▆▇▇█▇▆▆▆▇▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▂▁▁▃▃▃▃▂▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▇██▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss ▆▆▇█▇▆▆▇▇▆▅▅▅▄▅▄▄▄▄▄▄▃▃▃▂▃▂▂▂▂▃▂▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▇▇▅▇██▆▅▄▆▄▄▇▅▄▅▇▃▅▄▄▄▃▂▃▂▂▂▃▃▃▂▂▂▂▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▆█▇▇▆▆▅▅▅▄▄▄▃▄▃▄▃▃▃▄▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▅▅▅██▇▆▆▄▄▅▅▆▅▅▄▄▃▄▂▃▂▂▃▂▁▁▂▂▃▂▂▂▂▂▁▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 4e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.99056\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.76853\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.96712\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.96089\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 6.945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 2690988\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 3.978\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.73922\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 0.38666\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 0.93233\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 0.86105\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 0.40026\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 0.98771\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250811_031106-ln7l1hqi\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20250811_031106-ln7l1hqi/logs\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증\n",
        "!yolo detect val model=runs/detect/train2/weights/best.pt data={BASE}/data.yaml imgsz=640\n",
        "\n",
        "# 샘플 시각화(선택)\n",
        "!yolo detect predict model=runs/detect/train2/weights/best.pt source={BASE}/val/images conf=0.25 iou=0.45 save=True\n",
        "\n",
        "# 클래스 확인\n",
        "from ultralytics import YOLO\n",
        "m = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
        "print(\"model.names:\", m.names)  # {0:'hand',1:'backpack',2:'handbag',3:'suitcase'} 기대\n",
        "\n",
        "# 다운로드\n",
        "from google.colab import files\n",
        "files.download(\"runs/detect/train2/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "iqZEYf5Z-XAy",
        "outputId": "0d7d63fb-b0a1-4e0a-aebe-d8468c43c38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.0 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hand_dataset/val/labels.cache... 58 images, 0 backgrounds, 0 corrupt: 100% 58/58 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:01<00:00,  2.42it/s]\n",
            "                   all         58        179      0.967      0.961      0.991      0.768\n",
            "                  hand         58        179      0.967      0.961      0.991      0.768\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 0.0ms loss, 5.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics 8.3.0 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n",
            "\n",
            "image 1/58 /content/hand_dataset/val/images/CARDS_COURTYARD_S_H_frame_1054_jpg.rf.f91470b58278ac6f1e56b91c87a935ff.jpg: 384x640 2 hands, 41.0ms\n",
            "image 2/58 /content/hand_dataset/val/images/CARDS_COURTYARD_S_H_frame_2165_jpg.rf.bd435caea2048c037c0b10d2d6955613.jpg: 384x640 3 hands, 6.9ms\n",
            "image 3/58 /content/hand_dataset/val/images/CARDS_LIVINGROOM_B_T_frame_0374_jpg.rf.4c9f5356bfd2fe7fa6d0c7e5f7cc7feb.jpg: 384x640 4 hands, 6.3ms\n",
            "image 4/58 /content/hand_dataset/val/images/CARDS_LIVINGROOM_H_S_frame_1322_jpg.rf.3096a186973a0983541f6af55f7aba0b.jpg: 384x640 5 hands, 6.7ms\n",
            "image 5/58 /content/hand_dataset/val/images/CARDS_LIVINGROOM_T_B_frame_2273_jpg.rf.a3f4697b91561c3dab4aca964eaf13de.jpg: 384x640 2 hands, 6.2ms\n",
            "image 6/58 /content/hand_dataset/val/images/CARDS_OFFICE_B_S_frame_1674_jpg.rf.da760343a25c36078d4a0a99c6e41f15.jpg: 384x640 3 hands, 6.5ms\n",
            "image 7/58 /content/hand_dataset/val/images/CARDS_OFFICE_B_S_frame_2690_jpg.rf.cc890dbabeb8f05980db0d590ff5e88e.jpg: 384x640 4 hands, 6.4ms\n",
            "image 8/58 /content/hand_dataset/val/images/CARDS_OFFICE_T_H_frame_2116_jpg.rf.586e307de32fe5e7d9559684dedb76e4.jpg: 384x640 4 hands, 6.5ms\n",
            "image 9/58 /content/hand_dataset/val/images/CHESS_COURTYARD_B_T_frame_0413_jpg.rf.a3a3d7e4d40efc9209614b83a661cdb4.jpg: 384x640 3 hands, 6.4ms\n",
            "image 10/58 /content/hand_dataset/val/images/CHESS_COURTYARD_B_T_frame_0446_jpg.rf.d3ed18fc46b04eaeb9d0e0d6d687f567.jpg: 384x640 2 hands, 6.2ms\n",
            "image 11/58 /content/hand_dataset/val/images/CHESS_COURTYARD_B_T_frame_1110_jpg.rf.fc23abb80de77b1ff588891e6032f580.jpg: 384x640 2 hands, 6.0ms\n",
            "image 12/58 /content/hand_dataset/val/images/CHESS_COURTYARD_H_S_frame_0787_jpg.rf.b065ba2557637339210e47794207651e.jpg: 384x640 2 hands, 10.8ms\n",
            "image 13/58 /content/hand_dataset/val/images/CHESS_COURTYARD_H_S_frame_1297_jpg.rf.3c62abc5ec30506f78783d2b4ae25819.jpg: 384x640 3 hands, 9.0ms\n",
            "image 14/58 /content/hand_dataset/val/images/CHESS_COURTYARD_H_S_frame_2036_jpg.rf.17c461fbcd877468fd8572057f1bd6ff.jpg: 384x640 3 hands, 6.1ms\n",
            "image 15/58 /content/hand_dataset/val/images/CHESS_COURTYARD_S_H_frame_0453_jpg.rf.74b1804a7fc66e4b3a321afb0c4f7fb7.jpg: 384x640 2 hands, 6.0ms\n",
            "image 16/58 /content/hand_dataset/val/images/CHESS_COURTYARD_S_H_frame_2248_jpg.rf.e0e7936664617ca56fd6de1d2c1f333b.jpg: 384x640 2 hands, 6.2ms\n",
            "image 17/58 /content/hand_dataset/val/images/CHESS_COURTYARD_T_B_frame_1030_jpg.rf.7183851caea13c80b36fc1b1fa263426.jpg: 384x640 4 hands, 6.3ms\n",
            "image 18/58 /content/hand_dataset/val/images/CHESS_COURTYARD_T_B_frame_1194_jpg.rf.5cac6bdacc5fe5dfc608af9abbb6ddf5.jpg: 384x640 3 hands, 6.3ms\n",
            "image 19/58 /content/hand_dataset/val/images/CHESS_COURTYARD_T_B_frame_2546_jpg.rf.cdaf79bdcaabcb5f024f24530028f320.jpg: 384x640 4 hands, 6.3ms\n",
            "image 20/58 /content/hand_dataset/val/images/CHESS_OFFICE_B_S_frame_1535_jpg.rf.42159b1e4111903a09420afc3e3286a6.jpg: 384x640 4 hands, 6.1ms\n",
            "image 21/58 /content/hand_dataset/val/images/CHESS_OFFICE_B_S_frame_1915_jpg.rf.b037387a9c4c5663ab3f9af9cbb3c4c6.jpg: 384x640 3 hands, 6.2ms\n",
            "image 22/58 /content/hand_dataset/val/images/CHESS_OFFICE_H_T_frame_0693_jpg.rf.0ccee3e84f0d751c5d718abbd34c9293.jpg: 384x640 3 hands, 6.2ms\n",
            "image 23/58 /content/hand_dataset/val/images/CHESS_OFFICE_S_B_frame_1971_jpg.rf.d67d05549ba13f3d4800e95ea5b7cda8.jpg: 384x640 3 hands, 9.7ms\n",
            "image 24/58 /content/hand_dataset/val/images/CHESS_OFFICE_S_B_frame_2365_jpg.rf.228f876f7d6371b1225aae139e90e780.jpg: 384x640 2 hands, 7.5ms\n",
            "image 25/58 /content/hand_dataset/val/images/JENGA_COURTYARD_H_B_frame_2067_jpg.rf.baf066436cc4c8604dc64af3b2985d5f.jpg: 384x640 3 hands, 6.2ms\n",
            "image 26/58 /content/hand_dataset/val/images/JENGA_COURTYARD_H_B_frame_2087_jpg.rf.7134d68eec425c266a20b5adcbe057c6.jpg: 384x640 3 hands, 6.2ms\n",
            "image 27/58 /content/hand_dataset/val/images/JENGA_COURTYARD_S_T_frame_0813_jpg.rf.2917e50f7641658ddd39ddc71e5893ee.jpg: 384x640 4 hands, 6.4ms\n",
            "image 28/58 /content/hand_dataset/val/images/JENGA_COURTYARD_T_S_frame_1724_jpg.rf.71a7b06d5fb13ac04b418cb7b487ad84.jpg: 384x640 4 hands, 7.3ms\n",
            "image 29/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_B_H_frame_0784_jpg.rf.8140d4e9f08cad861c1d87b0e12ede64.jpg: 384x640 4 hands, 6.4ms\n",
            "image 30/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_B_H_frame_1185_jpg.rf.a4573e316e382b4bbeccc8983fd5b5ef.jpg: 384x640 4 hands, 6.2ms\n",
            "image 31/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_B_H_frame_1725_jpg.rf.d0eb7d8ef006fbb0f5e664f2c5718c73.jpg: 384x640 3 hands, 6.6ms\n",
            "image 32/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_H_B_frame_1425_jpg.rf.20c8a7581700814a4485bc141776e698.jpg: 384x640 1 hand, 6.6ms\n",
            "image 33/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_H_B_frame_1756_jpg.rf.566722ef918b3a83fe1f8983558a78ac.jpg: 384x640 4 hands, 6.9ms\n",
            "image 34/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_S_T_frame_0806_jpg.rf.fdc96738f5b3bd56d096db2bb5306e64.jpg: 384x640 2 hands, 6.7ms\n",
            "image 35/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_S_T_frame_0880_jpg.rf.64864a5cae51f5a80664421af47343d0.jpg: 384x640 4 hands, 6.4ms\n",
            "image 36/58 /content/hand_dataset/val/images/JENGA_LIVINGROOM_S_T_frame_2275_jpg.rf.611f28caf1db246fefe3ec049d9dfcc7.jpg: 384x640 4 hands, 7.1ms\n",
            "image 37/58 /content/hand_dataset/val/images/JENGA_OFFICE_S_B_frame_2573_jpg.rf.5209ab5ea582d724866bc065d9f7748f.jpg: 384x640 1 hand, 7.2ms\n",
            "image 38/58 /content/hand_dataset/val/images/JENGA_OFFICE_T_H_frame_1610_jpg.rf.6ba573834cc0d225f6622e7f3ff55118.jpg: 384x640 4 hands, 6.1ms\n",
            "image 39/58 /content/hand_dataset/val/images/JENGA_OFFICE_T_H_frame_1682_jpg.rf.7c06fd2f41ff51c0d6a010abeb1cb575.jpg: 384x640 3 hands, 6.4ms\n",
            "image 40/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_B_S_frame_1368_jpg.rf.bf21e17e67780b7625cc32fa87bc5b88.jpg: 384x640 4 hands, 6.3ms\n",
            "image 41/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_H_T_frame_1492_jpg.rf.c42eb255fddeaf955d4a9b006375c69c.jpg: 384x640 4 hands, 6.1ms\n",
            "image 42/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_S_B_frame_1906_jpg.rf.84fd2b46b1c19e93dd6ccbec8ef49c4b.jpg: 384x640 4 hands, 6.4ms\n",
            "image 43/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_0878_jpg.rf.93b2ba5631b7c806dac72d0cf5425e40.jpg: 384x640 3 hands, 6.6ms\n",
            "image 44/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_1037_jpg.rf.ee5d1d5edce69b6bbd02fdd1bb897197.jpg: 384x640 2 hands, 6.3ms\n",
            "image 45/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_1281_jpg.rf.7d81546e8de75e82752d3a5afb6e777d.jpg: 384x640 2 hands, 6.5ms\n",
            "image 46/58 /content/hand_dataset/val/images/PUZZLE_COURTYARD_T_H_frame_1894_jpg.rf.00efae11da8a6c9fa6b1fca4e2c9f66f.jpg: 384x640 3 hands, 6.3ms\n",
            "image 47/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_B_T_frame_1279_jpg.rf.ab5f9c49880d2ccd8db9b4dfccec0e00.jpg: 384x640 4 hands, 6.2ms\n",
            "image 48/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_H_S_frame_1162_jpg.rf.5e3b1c555b60f7909c727ad1a2d24684.jpg: 384x640 1 hand, 6.1ms\n",
            "image 49/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_S_H_frame_0381_jpg.rf.3e42cb3f93048afb67924fe598f25d8c.jpg: 384x640 3 hands, 8.3ms\n",
            "image 50/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_S_H_frame_1607_jpg.rf.54fb53b8024faf86d7feddb4e56b03a7.jpg: 384x640 2 hands, 6.4ms\n",
            "image 51/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_S_H_frame_2352_jpg.rf.07783dc544293177f5566c857027c6aa.jpg: 384x640 4 hands, 6.2ms\n",
            "image 52/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_T_B_frame_1582_jpg.rf.3d7bfd0e4255e2ec50027e7164006410.jpg: 384x640 4 hands, 6.1ms\n",
            "image 53/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_T_B_frame_2151_jpg.rf.ed2752504e1745a8218276e0c2b112ed.jpg: 384x640 3 hands, 6.2ms\n",
            "image 54/58 /content/hand_dataset/val/images/PUZZLE_LIVINGROOM_T_B_frame_2567_jpg.rf.ca25ec8413398f59907a2120e53375f0.jpg: 384x640 3 hands, 6.1ms\n",
            "image 55/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_B_H_frame_2537_jpg.rf.e22dcb5a43b77e8748df1ba3265ce42d.jpg: 384x640 3 hands, 6.2ms\n",
            "image 56/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_H_B_frame_1977_jpg.rf.9d65b4edcfc134c078857da47c138e47.jpg: 384x640 4 hands, 8.1ms\n",
            "image 57/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_H_B_frame_2319_jpg.rf.adb78752e0a44c15f0ccebdf416baa2b.jpg: 384x640 1 hand, 7.2ms\n",
            "image 58/58 /content/hand_dataset/val/images/PUZZLE_OFFICE_T_S_frame_0378_jpg.rf.3b9927a17fa5727d181e9c0c80549914.jpg: 384x640 4 hands, 6.2ms\n",
            "Speed: 1.7ms preprocess, 7.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n",
            "model.names: {0: 'hand', 1: 'backpack', 2: 'handbag', 3: 'suitcase'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42c7076c-f8cb-46af-b224-7eb001927fdf\", \"best.pt\", 5598767)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}