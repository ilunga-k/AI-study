{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilunga-k/AI-study/blob/main/Colab_%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ÏóÖÎ°úÎìú & ÏïïÏ∂ï Ìï¥Ï†ú ---\n",
        "import os, glob, zipfile, shutil\n",
        "from google.colab import files\n",
        "\n",
        "BASE = \"/content\"\n",
        "HAND_ROOT = f\"{BASE}/hand_dataset\"  # ÌëúÏ§Ä ÏúÑÏπò\n",
        "\n",
        "print(\"hand Îç∞Ïù¥ÌÑ∞ÏÖã zip ÌååÏùºÏùÑ ÏÑ†ÌÉùÌï¥Ï§ò.\")\n",
        "up = files.upload()  # Ïòà: hand_dataset.zip\n",
        "zip_path = os.path.join(BASE, list(up.keys())[0])\n",
        "\n",
        "# Í∏∞Ï°¥ Ìè¥Îçî ÏûàÏúºÎ©¥ Ï†úÍ±∞\n",
        "if os.path.exists(HAND_ROOT):\n",
        "    shutil.rmtree(HAND_ROOT)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(BASE)\n",
        "\n",
        "# --- Î£®Ìä∏ ÏûêÎèô ÌÉêÏßÄ: train/val(ÎòêÎäî vaild/valid) ÏïàÏóê images/labelsÍ∞Ä ÏûàÎäî Ìè¥Îçî Ï∞æÍ∏∞ ---\n",
        "def looks_like_root(p):\n",
        "    def ok(sp):\n",
        "        return os.path.isdir(f\"{p}/{sp}/images\") and os.path.isdir(f\"{p}/{sp}/labels\")\n",
        "    # train ÏùÄ ÌïÑÏàò, Í≤ÄÏ¶ùÏùÄ val / valid / vaild Ï§ë ÌïòÎÇòÎßå ÏûàÏñ¥ÎèÑ OK\n",
        "    return ok(\"train\") and any(ok(v) for v in [\"val\",\"valid\",\"vaild\"])\n",
        "\n",
        "cands = [d for d in glob.glob(f\"{BASE}/*\") if os.path.isdir(d)]\n",
        "src_root = next((d for d in sorted(cands, key=len) if looks_like_root(d)), None)\n",
        "assert src_root, \"Îç∞Ïù¥ÌÑ∞ Î£®Ìä∏Î•º Ï∞æÏßÄ Î™ªÌñàÏñ¥. zip ÎÇ¥Î∂Ä Íµ¨Ï°∞(‚Ä¶/train/images, ‚Ä¶/train/labels)Î•º ÌôïÏù∏Ìï¥Ï§ò.\"\n",
        "\n",
        "# ÌëúÏ§Ä Í≤ΩÎ°úÎ°ú Ïù¥Îèô\n",
        "shutil.move(src_root, HAND_ROOT)\n",
        "\n",
        "# --- Ïò§ÌÉàÏûê Ìè¥ÎçîÎ™Ö ÍµêÏ†ï: valid, vaild -> val ---\n",
        "for wrong in [\"valid\",\"vaild\"]:\n",
        "    if os.path.exists(f\"{HAND_ROOT}/{wrong}\") and not os.path.exists(f\"{HAND_ROOT}/val\"):\n",
        "        shutil.move(f\"{HAND_ROOT}/{wrong}\", f\"{HAND_ROOT}/val\")\n",
        "\n",
        "# ÏµúÏ¢Ö Íµ¨Ï°∞ ÌôïÏù∏\n",
        "assert os.path.isdir(f\"{HAND_ROOT}/train/images\") and os.path.isdir(f\"{HAND_ROOT}/train/labels\"), \"train Ìè¥Îçî Íµ¨Ï°∞ Ïò§Î•ò\"\n",
        "assert os.path.isdir(f\"{HAND_ROOT}/val/images\")   and os.path.isdir(f\"{HAND_ROOT}/val/labels\"),   \"val Ìè¥Îçî Íµ¨Ï°∞ Ïò§Î•ò\"\n",
        "print(\"‚úÖ hand Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï°∞ OK ‚Üí\", HAND_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "dV5fVyYf9fYY",
        "outputId": "e493e653-37aa-4791-deda-39f80bf29d5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hand Îç∞Ïù¥ÌÑ∞ÏÖã zip ÌååÏùºÏùÑ ÏÑ†ÌÉùÌï¥Ï§ò.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-269be21d-5fb7-4c19-9302-557dbb24ac49\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-269be21d-5fb7-4c19-9302-557dbb24ac49\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hand_dataset.zip to hand_dataset.zip\n",
            "‚úÖ hand Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï°∞ OK ‚Üí /content/hand_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, urllib.request\n",
        "\n",
        "BASE = \"/content\"\n",
        "COCO_DIR = f\"{BASE}/coco2017\"\n",
        "os.makedirs(COCO_DIR, exist_ok=True)\n",
        "\n",
        "files = {\n",
        "    \"train_images\": (\"http://images.cocodataset.org/zips/train2017.zip\", f\"{COCO_DIR}/train2017.zip\"),\n",
        "    \"val_images\":   (\"http://images.cocodataset.org/zips/val2017.zip\",   f\"{COCO_DIR}/val2017.zip\"),\n",
        "    \"ann\":          (\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\", f\"{COCO_DIR}/ann.zip\"),\n",
        "}\n",
        "for name, (url, path) in files.items():\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"downloading {name} ...\")\n",
        "        urllib.request.urlretrieve(url, path)\n",
        "\n",
        "def unzip(p, to):\n",
        "    with zipfile.ZipFile(p, 'r') as zf: zf.extractall(to)\n",
        "\n",
        "if not os.path.isdir(f\"{COCO_DIR}/train2017\"): unzip(files[\"train_images\"][1], COCO_DIR)\n",
        "if not os.path.isdir(f\"{COCO_DIR}/val2017\"):   unzip(files[\"val_images\"][1],   COCO_DIR)\n",
        "if not os.path.isdir(f\"{COCO_DIR}/annotations\"):unzip(files[\"ann\"][1],          COCO_DIR)\n",
        "print(\"COCO ready:\", os.listdir(COCO_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8EpErSm_WCn",
        "outputId": "fa514b60-2fca-4161-f42d-7c59205b7a21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading train_images ...\n",
            "downloading val_images ...\n",
            "downloading ann ...\n",
            "COCO ready: ['annotations', 'val2017', 'val2017.zip', 'ann.zip', 'train2017', 'train2017.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, shutil, math\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# ÏÉùÏÑ±Îê† Í∞ÄÎ∞© Ï†ÑÏö© Îç∞Ïù¥ÌÑ∞ÏÖã\n",
        "ITEMS_ROOT = f\"{BASE}/items_dataset\"\n",
        "for sp in [\"train\",\"val\"]:\n",
        "    os.makedirs(f\"{ITEMS_ROOT}/{sp}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{ITEMS_ROOT}/{sp}/labels\", exist_ok=True)\n",
        "\n",
        "# Ï†ÑÏó≠ ÌÅ¥ÎûòÏä§ Îß§Ìïë(Íº≠ Ïú†ÏßÄ)\n",
        "GLOBAL_IDX = {\"backpack\":1, \"handbag\":2, \"suitcase\":3}\n",
        "\n",
        "# Î≥ÄÌôò ÌååÎùºÎØ∏ÌÑ∞\n",
        "MIN_AREA_RATIO = 0.005   # ÌîÑÎ†àÏûÑ ÎåÄÎπÑ ÎÑàÎ¨¥ ÏûëÏùÄ Î∞ïÏä§ Ï†úÍ±∞(ÏÑ†ÌÉù)\n",
        "INCLUDE_NEGATIVES = False # TrueÎ©¥ ÌÉÄÍ≤üÏóÜÎäî Ïù¥ÎØ∏ÏßÄÏóê Îπà ÎùºÎ≤® ÌååÏùº ÏÉùÏÑ±(Ïò§ÌÉê ÏñµÏ†úÏö©)\n",
        "\n",
        "def coco_to_yolo_split(coco_json_path, img_dir, out_split_dir):\n",
        "    coco = COCO(coco_json_path)\n",
        "    # COCO catId Îß§Ìïë\n",
        "    name_to_cat = {cat[\"name\"]:cat[\"id\"] for cat in coco.loadCats(coco.getCatIds())}\n",
        "    target_cats = [name_to_cat[n] for n in [\"backpack\",\"handbag\",\"suitcase\"] if n in name_to_cat]\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄ Î©îÌÉÄ\n",
        "    imgs = {img[\"id\"]:img for img in coco.loadImgs(coco.getImgIds())}\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄÎ≥Ñ ÎùºÎ≤® ÎàÑÏ†Å\n",
        "    img_to_lines = {img_id: [] for img_id in imgs.keys()}\n",
        "    ann_ids = coco.getAnnIds(catIds=target_cats, iscrowd=None)\n",
        "    anns = coco.loadAnns(ann_ids)\n",
        "\n",
        "    for a in anns:\n",
        "        img_id = a[\"image_id\"]\n",
        "        img_meta = imgs[img_id]\n",
        "        W, H = img_meta[\"width\"], img_meta[\"height\"]\n",
        "        x, y, w, h = a[\"bbox\"]  # COCO: Ï¢åÏÉÅÎã® x,y, w,h (ÌîΩÏÖÄ)\n",
        "        if w <= 1 or h <= 1:\n",
        "            continue\n",
        "        if (w*h)/(W*H) < MIN_AREA_RATIO:\n",
        "            continue\n",
        "        # Ï†ïÍ∑úÌôîÎêú YOLO(cx,cy,w,h)\n",
        "        cx = (x + w/2) / W\n",
        "        cy = (y + h/2) / H\n",
        "        nw = w / W\n",
        "        nh = h / H\n",
        "\n",
        "        cat_name = coco.loadCats([a[\"category_id\"]])[0][\"name\"]\n",
        "        cls = GLOBAL_IDX.get(cat_name, None)\n",
        "        if cls is None:\n",
        "            continue\n",
        "        img_to_lines[img_id].append(f\"{cls} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\")\n",
        "\n",
        "    # ÎùºÎ≤®/Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•\n",
        "    save_img_dir = f\"{out_split_dir}/images\"\n",
        "    save_lbl_dir = f\"{out_split_dir}/labels\"\n",
        "\n",
        "    pos_cnt = 0\n",
        "    for img_id, meta in imgs.items():\n",
        "        fname = meta[\"file_name\"]\n",
        "        src = os.path.join(img_dir, fname)\n",
        "        dst = os.path.join(save_img_dir, fname)\n",
        "\n",
        "        lines = img_to_lines[img_id]\n",
        "        if len(lines)==0 and not INCLUDE_NEGATIVES:\n",
        "            continue  # ÌÉÄÍ≤ü ÏóÜÎäî Ïù¥ÎØ∏ÏßÄÎäî Ïä§ÌÇµ(Í∏∞Î≥∏)\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î≥µÏÇ¨\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.copy2(src, dst)\n",
        "        # ÎùºÎ≤® Ï†ÄÏû•(ÎπÑÏñ¥ÏûàÏúºÎ©¥ Îπà ÌååÏùº)\n",
        "        lbl_path = os.path.join(save_lbl_dir, os.path.splitext(fname)[0] + \".txt\")\n",
        "        with open(lbl_path, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n",
        "        if lines: pos_cnt += 1\n",
        "\n",
        "    total_imgs = len([f for f in os.listdir(save_img_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "    print(f\"[{out_split_dir}] ÎùºÎ≤® ÏûàÎäî Ïù¥ÎØ∏ÏßÄ: {pos_cnt}, Ï†ÄÏû•Îêú Ïù¥ÎØ∏ÏßÄ Ï¥ùÍ≥Ñ: {total_imgs}\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "coco_to_yolo_split(f\"{COCO_DIR}/annotations/instances_train2017.json\", f\"{COCO_DIR}/train2017\", f\"{ITEMS_ROOT}/train\")\n",
        "coco_to_yolo_split(f\"{COCO_DIR}/annotations/instances_val2017.json\",   f\"{COCO_DIR}/val2017\",   f\"{ITEMS_ROOT}/val\")\n",
        "\n",
        "# Îã®ÎèÖ ÌÖåÏä§Ìä∏Ïö© items Ï†ÑÏö© data.yamlÎèÑ ÎßåÎì§Ïñ¥ Îë†\n",
        "open(f\"{ITEMS_ROOT}/data_items.yaml\",\"w\").write(f\"\"\"\\\n",
        "path: {ITEMS_ROOT}\n",
        "train: train/images\n",
        "val: val/images\n",
        "nc: 4\n",
        "names: [hand, backpack, handbag, suitcase]\n",
        "\"\"\")\n",
        "print(open(f\"{ITEMS_ROOT}/data_items.yaml\").read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xslfch17_aFH",
        "outputId": "8b4bf820-0617-49ef-c87b-22f0b40291ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=32.74s)\n",
            "creating index...\n",
            "index created!\n",
            "[/content/items_dataset/train] ÎùºÎ≤® ÏûàÎäî Ïù¥ÎØ∏ÏßÄ: 8823, Ï†ÄÏû•Îêú Ïù¥ÎØ∏ÏßÄ Ï¥ùÍ≥Ñ: 8823\n",
            "loading annotations into memory...\n",
            "Done (t=0.91s)\n",
            "creating index...\n",
            "index created!\n",
            "[/content/items_dataset/val] ÎùºÎ≤® ÏûàÎäî Ïù¥ÎØ∏ÏßÄ: 364, Ï†ÄÏû•Îêú Ïù¥ÎØ∏ÏßÄ Ï¥ùÍ≥Ñ: 364\n",
            "path: /content/items_dataset\n",
            "train: train/images\n",
            "val: val/images\n",
            "nc: 4\n",
            "names: [hand, backpack, handbag, suitcase]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "def force_class_zero(lbl_dir):\n",
        "    n_edit = 0\n",
        "    for p in pathlib.Path(lbl_dir).glob(\"*.txt\"):\n",
        "        lines_out = []\n",
        "        changed = False\n",
        "        for ln in p.read_text().splitlines():\n",
        "            ln = ln.strip()\n",
        "            if not ln:\n",
        "                continue\n",
        "            parts = ln.split()\n",
        "            if not parts:\n",
        "                continue\n",
        "            if parts[0] != \"0\":\n",
        "                parts[0] = \"0\"\n",
        "                changed = True\n",
        "            lines_out.append(\" \".join(parts))\n",
        "        p.write_text(\"\\n\".join(lines_out))\n",
        "        if changed: n_edit += 1\n",
        "    return n_edit\n",
        "\n",
        "edited_tr = force_class_zero(f\"{HAND_ROOT}/train/labels\")\n",
        "edited_va = force_class_zero(f\"{HAND_ROOT}/val/labels\")\n",
        "print(f\"hand ÎùºÎ≤® Í∞ïÏ†ú ÌÜµÏùº ÏôÑÎ£å: train ÏàòÏ†ï {edited_tr}Í∞ú, val ÏàòÏ†ï {edited_va}Í∞ú\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUW3cYga9jkw",
        "outputId": "9602285a-a1ca-4422-c4d0-188dc7c7448c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hand ÎùºÎ≤® Í∞ïÏ†ú ÌÜµÏùº ÏôÑÎ£å: train ÏàòÏ†ï 0Í∞ú, val ÏàòÏ†ï 0Í∞ú\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QWTNR5k_Fe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ITEMS_ROOT = f\"{BASE}/items_dataset\"\n",
        "assert os.path.isdir(f\"{ITEMS_ROOT}/train/images\") and os.path.isdir(f\"{ITEMS_ROOT}/train/labels\"), \\\n",
        "    \"items_datasetÏù¥ ÏóÜÏñ¥. Î®ºÏ†Ä COCO‚ÜíÍ∞ÄÎ∞©Î•ò Î≥ÄÌôò ÏΩîÎìúÎ•º Ïã§ÌñâÌï¥ /content/items_dataset Î•º ÎßåÎì§Ïñ¥Ï§ò.\"\n",
        "assert os.path.isdir(f\"{ITEMS_ROOT}/val/images\") and os.path.isdir(f\"{ITEMS_ROOT}/val/labels\"), \\\n",
        "    \"items_dataset val Íµ¨Ï°∞Í∞Ä ÌïÑÏöîÌï¥.\"\n",
        "print(\"‚úÖ items_dataset ÌôïÏù∏ OK ‚Üí\", ITEMS_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovvhr92L9lLH",
        "outputId": "d7bb1273-073a-488b-9a18-2f8b558f77d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ items_dataset ÌôïÏù∏ OK ‚Üí /content/items_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMBINED_YAML_PATH = f\"{BASE}/data_combined.yaml\"\n",
        "yaml_text = f\"\"\"\\\n",
        "path: .\n",
        "train:\n",
        "  - {HAND_ROOT}/train/images\n",
        "  - {ITEMS_ROOT}/train/images\n",
        "val:\n",
        "  - {HAND_ROOT}/val/images\n",
        "  - {ITEMS_ROOT}/val/images\n",
        "nc: 4\n",
        "names: [hand, backpack, handbag, suitcase]\n",
        "\"\"\"\n",
        "open(COMBINED_YAML_PATH, \"w\").write(yaml_text)\n",
        "print(\"‚úÖ data.yaml ÏÉùÏÑ±:\", COMBINED_YAML_PATH)\n",
        "print(yaml_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Wdntbn9nTN",
        "outputId": "bc571077-2907-4aca-d635-da44ea689d07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data.yaml ÏÉùÏÑ±: /content/data_combined.yaml\n",
            "path: .\n",
            "train:\n",
            "  - /content/hand_dataset/train/images\n",
            "  - /content/items_dataset/train/images\n",
            "val:\n",
            "  - /content/hand_dataset/val/images\n",
            "  - /content/items_dataset/val/images\n",
            "nc: 4\n",
            "names: [hand, backpack, handbag, suitcase]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "def count_labels(lbl_dirs):\n",
        "    cnt = {0:0,1:0,2:0,3:0}\n",
        "    for d in lbl_dirs:\n",
        "        for p in glob.glob(d+\"/*.txt\"):\n",
        "            for ln in open(p):\n",
        "                if ln.strip():\n",
        "                    cid = int(ln.split()[0])\n",
        "                    if cid in cnt: cnt[cid]+=1\n",
        "    return cnt\n",
        "\n",
        "print(\"[HAND train]\", count_labels([f\"{HAND_ROOT}/train/labels\"]))\n",
        "print(\"[ITEMS train]\", count_labels([f\"{ITEMS_ROOT}/train/labels\"]))\n",
        "print(\"[COMBINED train]\", count_labels([f\"{HAND_ROOT}/train/labels\", f\"{ITEMS_ROOT}/train/labels\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1xq9wB89pp7",
        "outputId": "13a30e16-877b-46f4-f0c6-87d7b6e3d4fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HAND train] {0: 1499, 1: 0, 2: 0, 3: 0}\n",
            "[ITEMS train] {0: 0, 1: 5036, 2: 6322, 3: 5041}\n",
            "[COMBINED train] {0: 1499, 1: 5036, 2: 6322, 3: 5041}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "# HAND_ROOT, ITEMS_ROOT Í∞Ä ÏïûÏóêÏÑú Ïù¥ÎØ∏ Ï†ïÏùòÎêòÏñ¥ ÏûàÎã§Îäî Ï†ÑÏ†ú\n",
        "# hand Ïò§Î≤ÑÏÉòÌîåÎßÅÏùÑ ÌñàÎã§Î©¥ train_x1, train_x2 ‚Ä¶ ÏûêÎèô Ìè¨Ìï®Îê®\n",
        "hand_train_paths = [f\"{HAND_ROOT}/train/images\"] + \\\n",
        "                   sorted(glob.glob(f\"{HAND_ROOT}/train_x*/images\"))\n",
        "\n",
        "train_paths = hand_train_paths + [f\"{ITEMS_ROOT}/train/images\"]\n",
        "val_paths   = [f\"{HAND_ROOT}/val/images\", f\"{ITEMS_ROOT}/val/images\"]\n",
        "\n",
        "COMBINED_YAML_PATH = \"/content/data_combined.yaml\"\n",
        "yaml_text = \"path: .\\ntrain:\\n\" + \\\n",
        "            \"\".join([f\"  - {p}\\n\" for p in train_paths]) + \\\n",
        "            \"val:\\n\" + \\\n",
        "            \"\".join([f\"  - {p}\\n\" for p in val_paths]) + \\\n",
        "            \"nc: 4\\nnames: [hand, backpack, handbag, suitcase]\\n\"\n",
        "\n",
        "open(COMBINED_YAML_PATH, \"w\").write(yaml_text)\n",
        "print(\"‚úÖ data_combined.yaml ÏÉùÏÑ±/Í∞±Ïã† ÏôÑÎ£å:\\n\", yaml_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG5X37Jo9vC0",
        "outputId": "b53c8729-6a77-42f0-9797-f6caebb595d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ data_combined.yaml ÏÉùÏÑ±/Í∞±Ïã† ÏôÑÎ£å:\n",
            " path: .\n",
            "train:\n",
            "  - /content/hand_dataset/train/images\n",
            "  - /content/items_dataset/train/images\n",
            "val:\n",
            "  - /content/hand_dataset/val/images\n",
            "  - /content/items_dataset/val/images\n",
            "nc: 4\n",
            "names: [hand, backpack, handbag, suitcase]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Ï∂©Îèå Í∞ÄÎä• Ìå®ÌÇ§ÏßÄ Ï†úÍ±∞\n",
        "!pip -q uninstall -y numpy ultralytics opencv-python opencv-contrib-python opencv-python-headless pycocotools fastai thinc spacy >/dev/null\n",
        "\n",
        "# 2) Ìò∏Ìôò Ï°∞Ìï© \"Í≥†Ï†ï\" ÏÑ§Ïπò (Ultralytics 8.3.0 + NumPy 1.26.4 + OpenCV headless 4.11.0.86 + COCOÌà¥Ï¶à)\n",
        "!pip -q install --no-cache-dir numpy==1.26.4 ultralytics==8.3.0 opencv-python-headless==4.11.0.86 pycocotools==2.0.7 >/dev/null\n",
        "\n",
        "import numpy as _np, os\n",
        "print(\"NumPy:\", _np.__version__)  # 1.26.4 Ïó¨Ïïº Ï†ïÏÉÅ\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"  # W&B ÏßàÎ¨∏ ÎßâÍ∏∞\n",
        "\n",
        "# 3) ÌååÏù¥Ïç¨ Ïª§ÎÑê Í∞ïÏ†ú Ïû¨ÏãúÏûë(Ï§ëÏöî!)\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6B85oyxCuC5",
        "outputId": "cb6eed9f-7edb-4cb1-bf7c-752fe09ba07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping fastai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping thinc as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMBINED_YAML_PATH = \"/content/data_combined.yaml\"   # ÎÑ§Í∞Ä ÎßåÎì† ÌÜµÌï© YAML Í≤ΩÎ°úÎ°ú ÎßûÏ∂∞Ï£ºÏÑ∏Ïöî\n",
        "import os\n",
        "assert os.path.exists(COMBINED_YAML_PATH), f\"YAMLÏù¥ ÏóÜÏñ¥Ïöî: {COMBINED_YAML_PATH}\"\n",
        "print(\"YAML OK:\", COMBINED_YAML_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KzcA1aHELSN",
        "outputId": "60c1a747-2101-4daa-f21e-565571fb9e68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML OK: /content/data_combined.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "VOcPn1PSF4HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- wandb ÏôÑÏ†Ñ Ï†úÍ±∞ ---\n",
        "!pip -q uninstall -y wandb\n",
        "\n",
        "# --- W&B ÎπÑÌôúÏÑ±Ìôî ÌôòÍ≤ΩÎ≥ÄÏàò(Ïù¥ ÏÖÄÏùÄ Ìï≠ÏÉÅ import Ï†ÑÏóê!) ---\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "os.environ[\"WANDB_SILENT\"] = \"true\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th13FM5uFTzV",
        "outputId": "78190eef-9524-4660-80a1-1d386c907e34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics.utils import SETTINGS\n",
        "SETTINGS.update({'wandb': False})\n",
        "print(\"Ultralytics wandb setting:\", SETTINGS.get('wandb'))\n",
        "# Ï∂úÎ†•Ïù¥ FalseÎ©¥ Ï†ïÏÉÅ\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YZRgi9UFtC5",
        "outputId": "f2c85d50-49f9-4820-f088-f32902fa0a9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics wandb setting: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, textwrap\n",
        "\n",
        "# ÎãπÏã†Ïù¥ ÎßåÎì† Ìè¥Îçî ÏúÑÏπòÎ°ú ÎßûÏ∂∞Ï£ºÏÑ∏Ïöî\n",
        "HAND_ROOT  = \"/content/hand_dataset\"\n",
        "ITEMS_ROOT = \"/content/items_dataset\"\n",
        "\n",
        "COMBINED_YAML_PATH = \"/content/data_combined.yaml\"\n",
        "\n",
        "# YAMLÏù¥ ÏóÜÏúºÎ©¥ ÏÉùÏÑ±(Ïù¥ÎØ∏ ÏûàÎã§Î©¥ Í±¥ÎÑàÎúÄ)\n",
        "if not os.path.exists(COMBINED_YAML_PATH):\n",
        "    yaml_text = textwrap.dedent(f\"\"\"\n",
        "    path: /content\n",
        "    train:\n",
        "      - {HAND_ROOT}/train/images\n",
        "      - {ITEMS_ROOT}/train/images\n",
        "    val:\n",
        "      - {HAND_ROOT}/val/images\n",
        "      - {ITEMS_ROOT}/val/images\n",
        "    nc: 4\n",
        "    names: [hand, backpack, handbag, suitcase]\n",
        "    \"\"\").strip() + \"\\n\"\n",
        "    with open(COMBINED_YAML_PATH, \"w\") as f:\n",
        "        f.write(yaml_text)\n",
        "\n",
        "print(\"YAML @\", COMBINED_YAML_PATH)\n",
        "print(open(COMBINED_YAML_PATH).read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjW1hJsB9x5N",
        "outputId": "2dde5e8b-f68a-46d9-8fd8-29b4781aed24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML @ /content/data_combined.yaml\n",
            "path: .\n",
            "train:\n",
            "  - /content/hand_dataset/train/images\n",
            "  - /content/items_dataset/train/images\n",
            "val:\n",
            "  - /content/hand_dataset/val/images\n",
            "  - /content/items_dataset/val/images\n",
            "nc: 4\n",
            "names: [hand, backpack, handbag, suitcase]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")  # ÌïÑÏöîÏãú Îã§Î•∏ ÏÇ¨Ï†ÑÌïôÏäµ Í∞ÄÏ§ëÏπò ÏÇ¨Ïö©\n",
        "model.train(\n",
        "    data=COMBINED_YAML_PATH,\n",
        "    epochs=20, imgsz=640, batch=8,\n",
        "    lr0=0.002, weight_decay=0.0005,\n",
        "    freeze=10,                      # Î∞±Î≥∏ Í≥†Ï†ï\n",
        "    mosaic=0.8, mixup=0.05, degrees=5, translate=0.10, scale=0.5, shear=2,\n",
        "    cache=True, name=\"hand_items_freeze\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ahM-Oc4P9zKp",
        "outputId": "ba1e9c98-1fa5-4fa9-d242-7fbb36f5c1ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.178 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.0 üöÄ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/data_combined.yaml, epochs=20, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=hand_items_freeze4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.002, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5, translate=0.1, scale=0.5, shear=2, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.8, mixup=0.05, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/hand_items_freeze4\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 249 layers, 2,690,988 parameters, 2,690,972 gradients, 6.9 GFLOPs\n",
            "\n",
            "Transferred 313/391 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/hand_items_freeze4', view at http://localhost:6006/\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/hand_dataset/train/labels... 9314 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9314/9314 [00:28<00:00, 332.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/hand_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.6GB RAM required to cache images with 50% safety margin but only 10.9/12.7GB available, not caching images ‚ö†Ô∏è\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/hand_dataset/val/labels... 422 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 422/422 [00:01<00:00, 301.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/hand_dataset/val/labels.cache\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 422/422 [00:07<00:00, 59.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/hand_items_freeze4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.002' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/hand_items_freeze4\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20         0G      1.455       4.16      1.521         23        640:   4%|‚ñç         | 52/1165 [03:55<1:24:00,  4.53s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1618070894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov8n.pt\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ÌïÑÏöîÏãú Îã§Î•∏ ÏÇ¨Ï†ÑÌïôÏäµ Í∞ÄÏ§ëÏπò ÏÇ¨Ïö©\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.train(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOMBINED_YAML_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"\"\"Forward pass through Ghost Convolution block.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"\"\"Forward pass through Ghost Convolution block.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         return F.max_pool2d(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft = YOLO(\"runs/detect/hand_items_freeze/weights/best.pt\")\n",
        "ft.train(\n",
        "    data=COMBINED_YAML_PATH,\n",
        "    epochs=40, imgsz=640, batch=8,\n",
        "    lr0=0.001, weight_decay=0.0005,\n",
        "    freeze=None,                    # Í≥†Ï†ï Ìï¥Ï†ú\n",
        "    mosaic=0.6, mixup=0.0, degrees=5, translate=0.10, scale=0.5, shear=2,\n",
        "    cache=True, name=\"hand_items_finetune\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "KAzlCloC90T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_val = YOLO(\"runs/detect/hand_items_finetune/weights/best.pt\")\n",
        "ft_val.val(data=COMBINED_YAML_PATH, imgsz=640)\n",
        "\n",
        "# ColabÏù¥ÎùºÎ©¥:\n",
        "#from google.colab import files\n",
        "#files.download(\"runs/detect/hand_items_finetune/weights/best.pt\")\n"
      ],
      "metadata": {
        "id": "G7_I6IF6GWSj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab ÏãúÏûëÌïòÍ∏∞",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}